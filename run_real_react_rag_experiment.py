#!/usr/bin/env python3
"""
çœŸå®ReAct RAG Agent vs Baselineå®éªŒ
ä½¿ç”¨çœŸå®GPT-4o APIå’Œå®Œæ•´çš„query_kgæœºåˆ¶
"""

import sys
import time
import json
from pathlib import Path
sys.path.append('.')

from src.agents.baseline_agent import BaselineAgent
from src.agents.rag_agent import RAGAgent
from src.environments.textworld_env import TextWorldEnvironment
from src.knowledge.kg_builder import KnowledgeGraphBuilder
from src.knowledge.kg_retriever import KnowledgeGraphRetriever
from src.utils.logger import get_logger

def create_comprehensive_dodaf_kg():
    """åˆ›å»ºå…¨é¢çš„DODAFçŸ¥è¯†å›¾è°±"""
    kg = KnowledgeGraphBuilder('real_react_kg')
    
    print("ğŸ“š æ„å»ºDODAFçŸ¥è¯†å›¾è°±...")
    
    # DA (Condition) - çŠ¶æ€å’Œæ¡ä»¶
    kg.add_fact('kitchen', 'contains', 'key', dodaf_type='DA')
    kg.add_fact('kitchen', 'contains', 'apple', dodaf_type='DA')
    kg.add_fact('kitchen', 'contains', 'fridge', dodaf_type='DA')
    kg.add_fact('chest', 'location', 'bedroom', dodaf_type='DA')
    kg.add_fact('living_room', 'connects', 'kitchen_and_bedroom', dodaf_type='DA')
    kg.add_fact('player', 'starts_in', 'kitchen', dodaf_type='DA')
    
    # DO (Action) - åŠ¨ä½œå’Œæ“ä½œ
    kg.add_fact('take', 'enables', 'key_possession', dodaf_type='DO')
    kg.add_fact('key', 'opens', 'chest', dodaf_type='DO')
    kg.add_fact('go_north', 'leads_to', 'living_room', dodaf_type='DO')
    kg.add_fact('go_east', 'leads_to', 'bedroom', dodaf_type='DO')
    kg.add_fact('open', 'works_with', 'chest', dodaf_type='DO')
    kg.add_fact('inventory', 'shows', 'carried_items', dodaf_type='DO')
    
    # F (Outcome) - ç»“æœå’Œç›®æ ‡
    kg.add_fact('goal', 'is', 'open_chest_in_bedroom', dodaf_type='F')
    kg.add_fact('success', 'requires', 'key_and_chest_access', dodaf_type='F')
    kg.add_fact('treasure', 'obtained_by', 'opening_chest', dodaf_type='F')
    kg.add_fact('mission_complete', 'when', 'chest_opened', dodaf_type='F')
    
    print(f"âœ… DODAFçŸ¥è¯†å›¾è°±å®Œæˆ: {len(kg.facts)} ä¸ªäº‹å®")
    print("  DO (Action): 6ä¸ªåŠ¨ä½œäº‹å®")
    print("  DA (Condition): 6ä¸ªæ¡ä»¶äº‹å®") 
    print("  F (Outcome): 4ä¸ªç»“æœäº‹å®")
    
    return kg

def run_single_real_episode(agent, env, agent_name, episode_num, max_steps=25):
    """è¿è¡Œå•ä¸ªçœŸå®episode"""
    logger = get_logger(f"{agent_name}_Real")
    
    print(f"\nğŸ® {agent_name} Episode {episode_num} å¼€å§‹")
    print("-" * 50)
    
    # é‡ç½®ç¯å¢ƒå’ŒAgent
    observation = env.reset()
    if hasattr(agent, 'reset'):
        agent.reset()
    
    episode_data = {
        'episode_id': episode_num,
        'agent_type': agent_name,
        'actions_taken': [],
        'kg_queries': 0,
        'kg_hits': 0,
        'api_calls': 0,
        'api_response_times': [],
        'start_time': time.time()
    }
    
    total_reward = 0
    done = False
    step_count = 0
    
    print(f"åˆå§‹è§‚å¯Ÿ: {observation}")
    
    while not done and step_count < max_steps:
        available_actions = env.get_available_actions()
        
        print(f"\nStep {step_count + 1}:")
        print(f"  å¯ç”¨åŠ¨ä½œ: {available_actions}")
        
        # Agentå†³ç­–ï¼ˆçœŸå®APIè°ƒç”¨ï¼‰
        start_time = time.time()
        try:
            action = agent.act(observation, available_actions)
            api_time = time.time() - start_time
            
            print(f"  Agenté€‰æ‹©: '{action}' ({api_time:.2f}s)")
            
            episode_data['actions_taken'].append(action)
            episode_data['api_response_times'].append(api_time)
            
        except Exception as e:
            print(f"  âŒ Agentå†³ç­–å¤±è´¥: {e}")
            action = available_actions[0] if available_actions else "look"
            api_time = time.time() - start_time
        
        # æ‰§è¡ŒåŠ¨ä½œ
        observation, reward, done, info = env.step(action)
        total_reward += reward
        step_count += 1
        
        print(f"  æ‰§è¡Œç»“æœ: å¥–åŠ±={reward}, å®Œæˆ={done}")
        print(f"  æ–°è§‚å¯Ÿ: {observation}")
        
        if done and reward > 0:
            print(f"  ğŸ‰ {agent_name} æˆåŠŸå®Œæˆä»»åŠ¡ï¼")
            break
        elif reward < 0:
            print(f"  âš ï¸ è´Ÿå¥–åŠ±ï¼Œå¯èƒ½æ˜¯é”™è¯¯åŠ¨ä½œ")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    success = done and total_reward > 0
    completion_time = time.time() - episode_data['start_time']
    
    if hasattr(agent, 'get_stats'):
        stats = agent.get_stats()
        episode_data['kg_queries'] = stats.get('kg_queries', 0)
        episode_data['kg_hits'] = stats.get('kg_hits', 0)
        episode_data['api_calls'] = stats.get('api_calls', 0)
    
    episode_data.update({
        'success': success,
        'total_steps': step_count,
        'total_reward': total_reward,
        'completion_time': completion_time,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    })
    
    print(f"\nğŸ“Š Episode {episode_num} ç»“æœ:")
    print(f"  æˆåŠŸ: {success}")
    print(f"  æ€»æ­¥æ•°: {step_count}")
    print(f"  æ€»å¥–åŠ±: {total_reward:.3f}")
    print(f"  å®Œæˆæ—¶é—´: {completion_time:.1f}s")
    
    if episode_data['kg_queries'] > 0:
        hit_rate = episode_data['kg_hits'] / episode_data['kg_queries']
        print(f"  KGä½¿ç”¨: {episode_data['kg_queries']}æŸ¥è¯¢, {hit_rate:.2%}å‘½ä¸­ç‡")
    
    return episode_data

def run_real_react_rag_experiment():
    """è¿è¡ŒçœŸå®ReAct RAGå®éªŒ"""
    print("ğŸš€ çœŸå®ReAct RAG vs Baselineå®éªŒ")
    print("=" * 60)
    print("ä½¿ç”¨çœŸå®GPT-4o APIå’Œå®Œæ•´query_kgæœºåˆ¶")
    
    # åˆ›å»ºç¯å¢ƒ
    env = TextWorldEnvironment('real_react_exp', {
        'difficulty': 'easy',
        'max_episode_steps': 25
    })
    
    # åˆ›å»ºDODAFçŸ¥è¯†å›¾è°±
    kg = create_comprehensive_dodaf_kg()
    retriever = KnowledgeGraphRetriever(kg, 'real_react_retriever')
    
    # åˆ›å»ºAgents
    print(f"\nğŸ¤– åˆ›å»ºå¯¹æ¯”Agents...")
    
    # 1. Baseline Agent
    baseline_agent = BaselineAgent('real_baseline', {
        'model_name': 'gpt-4o',
        'use_local_model': False,
        'temperature': 0.7,
        'max_tokens': 100
    })
    print("âœ… Baseline Agentåˆ›å»º")
    
    # 2. ReAct RAG Agent
    react_rag_agent = RAGAgent('real_react_rag', {
        'model_name': 'gpt-4o',
        'use_local_model': False,
        'use_knowledge_graph': True,
        'use_react_reasoning': True,  # å¯ç”¨çœŸæ­£çš„ReAct
        'temperature': 0.7,
        'max_tokens': 250,  # å¢åŠ tokenä»¥æ”¯æŒReActæ¨ç†
        'max_kg_facts': 3
    })
    react_rag_agent.set_knowledge_retriever(retriever)
    print("âœ… ReAct RAG Agentåˆ›å»º")
    
    # è¿è¡Œå¯¹æ¯”å®éªŒ
    all_results = []
    episodes_per_agent = 4  # æ¯ç§Agentè¿è¡Œ4ä¸ªepisodes
    
    agents = [
        (baseline_agent, "Baseline_Real"),
        (react_rag_agent, "ReAct_RAG_Real")
    ]
    
    for agent, agent_name in agents:
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ è¿è¡Œ {agent_name} å®éªŒ ({episodes_per_agent} episodes)")
        print(f"{'='*60}")
        
        for episode in range(episodes_per_agent):
            result = run_single_real_episode(agent, env, agent_name, episode + 1)
            all_results.append(result)
            
            # çŸ­æš‚ä¼‘æ¯é¿å…APIé™åˆ¶
            if episode < episodes_per_agent - 1:
                print("â³ çŸ­æš‚ä¼‘æ¯...")
                time.sleep(2)
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
    output_dir = Path("results/real_react_rag_experiment")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    json_file = output_dir / f"react_rag_results_{timestamp}.json"
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print(f"\nğŸ“Š çœŸå®å®éªŒç»“æœå¯¹æ¯”:")
    print("=" * 60)
    
    for agent, agent_name in agents:
        agent_results = [r for r in all_results if r['agent_type'] == agent_name]
        
        if agent_results:
            success_rate = sum(1 for r in agent_results if r['success']) / len(agent_results)
            avg_steps = sum(r['total_steps'] for r in agent_results) / len(agent_results)
            avg_reward = sum(r['total_reward'] for r in agent_results) / len(agent_results)
            avg_time = sum(r['completion_time'] for r in agent_results) / len(agent_results)
            avg_api_time = sum(sum(r['api_response_times']) for r in agent_results) / len(agent_results)
            
            print(f"\n{agent_name}:")
            print(f"  Episodes: {len(agent_results)}")
            print(f"  æˆåŠŸç‡: {success_rate:.1%}")
            print(f"  å¹³å‡æ­¥æ•°: {avg_steps:.1f}")
            print(f"  å¹³å‡å¥–åŠ±: {avg_reward:.3f}")
            print(f"  å¹³å‡å®Œæˆæ—¶é—´: {avg_time:.1f}s")
            print(f"  å¹³å‡APIæ—¶é—´: {avg_api_time:.1f}s")
            
            # ReAct RAGç‰¹å®šç»Ÿè®¡
            if 'ReAct_RAG' in agent_name:
                total_kg_queries = sum(r['kg_queries'] for r in agent_results)
                total_kg_hits = sum(r['kg_hits'] for r in agent_results)
                if total_kg_queries > 0:
                    kg_hit_rate = total_kg_hits / total_kg_queries
                    print(f"  KGæŸ¥è¯¢ç»Ÿè®¡: {total_kg_queries}æ¬¡æŸ¥è¯¢, {kg_hit_rate:.2%}å‘½ä¸­ç‡")
                
                # æ˜¾ç¤ºæˆåŠŸæ¡ˆä¾‹çš„åŠ¨ä½œåºåˆ—
                successful = [r for r in agent_results if r['success']]
                if successful:
                    print(f"  æˆåŠŸæ¡ˆä¾‹åŠ¨ä½œåºåˆ—:")
                    for i, r in enumerate(successful):
                        print(f"    Episode {r['episode_id']}: {r['actions_taken']}")
    
    print(f"\nâœ… çœŸå®ReAct RAGå®éªŒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {json_file}")
    
    return json_file

if __name__ == "__main__":
    print("ğŸ¯ çœŸå®ReAct RAG Agentå®éªŒ")
    print("è¿™å°†ä½¿ç”¨:")
    print("  âœ… çœŸå®GPT-4o APIè°ƒç”¨")
    print("  âœ… çœŸæ­£çš„ReActå¾ªç¯ (Thought â†’ Action(query_kg) â†’ Observation)")
    print("  âœ… DODAFç»“æ„åŒ–çŸ¥è¯†å›¾è°±")
    print("  âœ… åŠ¨æ€query_kgæœºåˆ¶")
    print("  âœ… ä¸Baseline Agentå¯¹æ¯”")
    
    confirm = input("\nç¡®è®¤å¼€å§‹çœŸå®å®éªŒ? (y/N): ").strip().lower()
    if confirm == 'y':
        run_real_react_rag_experiment()
    else:
        print("å®éªŒå–æ¶ˆ")
