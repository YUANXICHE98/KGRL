#!/usr/bin/env python3
"""
åˆ†æbenchmarkæ•°æ®ç»“æ„
äº†è§£ALFWorldå’ŒTextWorldçš„çœŸå®æ•°æ®æ ¼å¼ï¼Œä¸ºè§„åˆ™æŠ½å–åšå‡†å¤‡
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def analyze_alfworld_data():
    """åˆ†æALFWorldæ•°æ®ç»“æ„"""
    print("ğŸ” åˆ†æALFWorldæ•°æ®ç»“æ„...")
    
    data_dir = Path(__file__).parent.parent
    alfworld_dir = data_dir / "benchmarks/alfworld"
    
    if not alfworld_dir.exists():
        print("âŒ ALFWorldç›®å½•ä¸å­˜åœ¨")
        return
    
    # åˆ†æå¸ƒå±€æ–‡ä»¶
    layout_dir = alfworld_dir / "alfworld/alfworld/gen/layouts"
    if layout_dir.exists():
        json_files = list(layout_dir.glob("*.json"))
        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªå¸ƒå±€æ–‡ä»¶")
        
        if json_files:
            # åˆ†æç¬¬ä¸€ä¸ªæ–‡ä»¶
            sample_file = json_files[0]
            print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {sample_file.name}")
            
            try:
                with open(sample_file, 'r') as f:
                    data = json.load(f)
                
                print(f"   - å¯¹è±¡æ•°é‡: {len(data)}")
                print("   - å¯¹è±¡ç±»å‹:")
                
                object_types = {}
                for key in data.keys():
                    obj_type = key.split('|')[0]
                    object_types[obj_type] = object_types.get(obj_type, 0) + 1
                
                for obj_type, count in sorted(object_types.items()):
                    print(f"     * {obj_type}: {count}")
                
                # æ˜¾ç¤ºå‡ ä¸ªç¤ºä¾‹
                print("   - ç¤ºä¾‹å¯¹è±¡:")
                for i, (key, value) in enumerate(list(data.items())[:3]):
                    print(f"     * {key}: {value}")
                
            except Exception as e:
                print(f"   âŒ è¯»å–å¤±è´¥: {e}")
    
    # åˆ†æPDDLæ–‡ä»¶
    pddl_dir = alfworld_dir / "alfworld/alfworld/gen/ff_planner/samples"
    if pddl_dir.exists():
        pddl_files = list(pddl_dir.glob("*.pddl"))
        print(f"\nğŸ“ æ‰¾åˆ° {len(pddl_files)} ä¸ªPDDLæ–‡ä»¶")
        
        if pddl_files:
            sample_file = pddl_files[0]
            print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {sample_file.name}")
            
            try:
                with open(sample_file, 'r') as f:
                    content = f.read()
                
                print(f"   - æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
                
                # åˆ†æå¯¹è±¡å®šä¹‰
                import re
                objects_match = re.search(r'\(:objects\s+(.*?)\)', content, re.DOTALL)
                if objects_match:
                    objects_text = objects_match.group(1)
                    lines = [line.strip() for line in objects_text.split('\n') if line.strip()]
                    print(f"   - å¯¹è±¡å®šä¹‰è¡Œæ•°: {len(lines)}")
                    
                    # ç»Ÿè®¡å¯¹è±¡ç±»å‹
                    object_types = {}
                    for line in lines:
                        if ' - ' in line:
                            _, type_part = line.split(' - ')
                            obj_type = type_part.strip()
                            object_types[obj_type] = object_types.get(obj_type, 0) + 1
                    
                    print("   - å¯¹è±¡ç±»å‹:")
                    for obj_type, count in sorted(object_types.items()):
                        print(f"     * {obj_type}: {count}")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¼€å¤´
                print("   - æ–‡ä»¶å¼€å¤´:")
                for i, line in enumerate(content.split('\n')[:10]):
                    print(f"     {i+1:2d}: {line}")
                
            except Exception as e:
                print(f"   âŒ è¯»å–å¤±è´¥: {e}")


def analyze_textworld_data():
    """åˆ†æTextWorldæ•°æ®ç»“æ„"""
    print("\nğŸ” åˆ†æTextWorldæ•°æ®ç»“æ„...")
    
    data_dir = Path(__file__).parent.parent
    textworld_dir = data_dir / "benchmarks/textworld"
    
    if not textworld_dir.exists():
        print("âŒ TextWorldç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾TextWorldæ–‡ä»¶
    print(f"ğŸ“ TextWorldç›®å½•å†…å®¹:")
    for item in textworld_dir.rglob("*"):
        if item.is_file() and item.suffix in ['.json', '.txt', '.py']:
            rel_path = item.relative_to(textworld_dir)
            print(f"   - {rel_path}")
    
    # å°è¯•ä½¿ç”¨TextWorld APIåˆ›å»ºç¤ºä¾‹æ¸¸æˆ
    try:
        import textworld
        print("\nğŸ® ä½¿ç”¨TextWorld APIåˆ›å»ºç¤ºä¾‹æ¸¸æˆ...")
        
        from textworld import GameMaker
        maker = GameMaker()
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¸¸æˆ
        print("   - åˆ›å»ºGameMakerå®ä¾‹æˆåŠŸ")
        print(f"   - å¯ç”¨æ–¹æ³•: {[m for m in dir(maker) if not m.startswith('_')][:10]}...")
        
        # å°è¯•åˆ›å»ºæˆ¿é—´å’Œç‰©å“
        try:
            # åˆ›å»ºæˆ¿é—´
            kitchen = maker.new_room("kitchen")
            living_room = maker.new_room("living_room")
            
            # è¿æ¥æˆ¿é—´
            path = maker.connect(kitchen.east, living_room.west)
            
            # åˆ›å»ºç‰©å“
            apple = maker.new(type='food', name='apple')
            kitchen.add(apple)
            
            print("   - æˆåŠŸåˆ›å»ºç¤ºä¾‹æ¸¸æˆç»“æ„")
            print(f"     * æˆ¿é—´: kitchen, living_room")
            print(f"     * ç‰©å“: apple")
            print(f"     * è¿æ¥: kitchen <-> living_room")
            
        except Exception as e:
            print(f"   âš ï¸  æ¸¸æˆåˆ›å»ºå¤±è´¥: {e}")
            
    except ImportError:
        print("   âš ï¸  TextWorldæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
    except Exception as e:
        print(f"   âŒ TextWorld APIæµ‹è¯•å¤±è´¥: {e}")


def analyze_existing_kg_data():
    """åˆ†æå·²æœ‰çš„çŸ¥è¯†å›¾è°±æ•°æ®"""
    print("\nğŸ” åˆ†æå·²æœ‰çš„çŸ¥è¯†å›¾è°±æ•°æ®...")
    
    data_dir = Path(__file__).parent.parent
    kg_dir = data_dir / "knowledge_graphs"
    
    if not kg_dir.exists():
        print("âŒ çŸ¥è¯†å›¾è°±ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾ç°æœ‰çš„çŸ¥è¯†å›¾è°±æ–‡ä»¶
    kg_files = []
    for ext in ['*.json', '*.graphml', '*.pickle']:
        kg_files.extend(kg_dir.rglob(ext))
    
    print(f"ğŸ“ æ‰¾åˆ° {len(kg_files)} ä¸ªçŸ¥è¯†å›¾è°±æ–‡ä»¶:")
    for kg_file in kg_files:
        rel_path = kg_file.relative_to(kg_dir)
        size = kg_file.stat().st_size
        print(f"   - {rel_path} ({size} bytes)")
        
        # å¦‚æœæ˜¯JSONæ–‡ä»¶ï¼Œå°è¯•åˆ†æå†…å®¹
        if kg_file.suffix == '.json':
            try:
                with open(kg_file, 'r') as f:
                    data = json.load(f)
                
                if isinstance(data, dict):
                    print(f"     * é”®: {list(data.keys())}")
                    if 'nodes' in data:
                        print(f"     * èŠ‚ç‚¹æ•°: {len(data['nodes'])}")
                    if 'edges' in data:
                        print(f"     * è¾¹æ•°: {len(data['edges'])}")
                        
            except Exception as e:
                print(f"     âŒ è¯»å–å¤±è´¥: {e}")


def generate_data_summary():
    """ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š...")
    
    data_dir = Path(__file__).parent.parent
    
    summary = {
        'alfworld': {
            'layout_files': 0,
            'pddl_files': 0,
            'total_objects': 0,
            'object_types': set()
        },
        'textworld': {
            'available': False,
            'api_working': False
        },
        'knowledge_graphs': {
            'existing_files': 0,
            'total_size_bytes': 0
        }
    }
    
    # ç»Ÿè®¡ALFWorldæ•°æ®
    alfworld_dir = data_dir / "benchmarks/alfworld"
    if alfworld_dir.exists():
        layout_dir = alfworld_dir / "alfworld/alfworld/gen/layouts"
        if layout_dir.exists():
            json_files = list(layout_dir.glob("*.json"))
            summary['alfworld']['layout_files'] = len(json_files)
            
            # ç»Ÿè®¡å¯¹è±¡
            for json_file in json_files[:5]:  # åªåˆ†æå‰5ä¸ªæ–‡ä»¶
                try:
                    with open(json_file, 'r') as f:
                        data = json.load(f)
                    summary['alfworld']['total_objects'] += len(data)
                    
                    for key in data.keys():
                        obj_type = key.split('|')[0]
                        summary['alfworld']['object_types'].add(obj_type)
                except:
                    pass
        
        pddl_dir = alfworld_dir / "alfworld/alfworld/gen/ff_planner/samples"
        if pddl_dir.exists():
            pddl_files = list(pddl_dir.glob("*.pddl"))
            summary['alfworld']['pddl_files'] = len(pddl_files)
    
    # æ£€æŸ¥TextWorld
    try:
        import textworld
        summary['textworld']['available'] = True
        
        from textworld import GameMaker
        maker = GameMaker()
        summary['textworld']['api_working'] = True
    except:
        pass
    
    # ç»Ÿè®¡çŸ¥è¯†å›¾è°±æ–‡ä»¶
    kg_dir = data_dir / "knowledge_graphs"
    if kg_dir.exists():
        kg_files = []
        for ext in ['*.json', '*.graphml', '*.pickle']:
            kg_files.extend(kg_dir.rglob(ext))
        
        summary['knowledge_graphs']['existing_files'] = len(kg_files)
        summary['knowledge_graphs']['total_size_bytes'] = sum(f.stat().st_size for f in kg_files)
    
    # è¾“å‡ºæ‘˜è¦
    print("ğŸ“‹ æ•°æ®æ‘˜è¦:")
    print(f"   ALFWorld:")
    print(f"     - å¸ƒå±€æ–‡ä»¶: {summary['alfworld']['layout_files']}")
    print(f"     - PDDLæ–‡ä»¶: {summary['alfworld']['pddl_files']}")
    print(f"     - æ€»å¯¹è±¡æ•°: {summary['alfworld']['total_objects']}")
    print(f"     - å¯¹è±¡ç±»å‹: {len(summary['alfworld']['object_types'])}")
    
    print(f"   TextWorld:")
    print(f"     - å¯ç”¨: {summary['textworld']['available']}")
    print(f"     - APIå·¥ä½œ: {summary['textworld']['api_working']}")
    
    print(f"   çŸ¥è¯†å›¾è°±:")
    print(f"     - ç°æœ‰æ–‡ä»¶: {summary['knowledge_graphs']['existing_files']}")
    print(f"     - æ€»å¤§å°: {summary['knowledge_graphs']['total_size_bytes']} bytes")
    
    # ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
    summary_file = data_dir / "extraction/data_summary.json"
    summary_file.parent.mkdir(parents=True, exist_ok=True)
    
    # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
    summary['alfworld']['object_types'] = list(summary['alfworld']['object_types'])
    
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nğŸ’¾ æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†æbenchmarkæ•°æ®ç»“æ„\n")
    
    # åˆ†æALFWorldæ•°æ®
    analyze_alfworld_data()
    
    # åˆ†æTextWorldæ•°æ®
    analyze_textworld_data()
    
    # åˆ†æå·²æœ‰çŸ¥è¯†å›¾è°±æ•°æ®
    analyze_existing_kg_data()
    
    # ç”Ÿæˆæ•°æ®æ‘˜è¦
    generate_data_summary()
    
    print("\nğŸ‰ æ•°æ®åˆ†æå®Œæˆ!")


if __name__ == "__main__":
    main()
