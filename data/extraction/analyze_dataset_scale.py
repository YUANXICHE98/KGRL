#!/usr/bin/env python3
"""
åˆ†ææ•°æ®é›†è§„æ¨¡
ç»Ÿè®¡ALFWorldå’ŒTextWorldçš„å®Œæ•´æ•°æ®é›†è§„æ¨¡
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def analyze_alfworld_scale():
    """åˆ†æALFWorldæ•°æ®é›†è§„æ¨¡"""
    print("ğŸ” åˆ†æALFWorldæ•°æ®é›†è§„æ¨¡...")
    
    data_dir = Path(__file__).parent.parent
    alfworld_dir = data_dir / "benchmarks/alfworld"
    
    if not alfworld_dir.exists():
        print("âŒ ALFWorldç›®å½•ä¸å­˜åœ¨")
        return {}
    
    stats = {
        'layout_files': 0,
        'pddl_files': 0,
        'domain_files': 0,
        'total_objects': 0,
        'unique_object_types': set(),
        'scenes': [],
        'sample_scenes': []
    }
    
    # åˆ†æå¸ƒå±€æ–‡ä»¶
    layout_dir = alfworld_dir / "alfworld/alfworld/gen/layouts"
    if layout_dir.exists():
        json_files = list(layout_dir.glob("*.json"))
        stats['layout_files'] = len(json_files)
        
        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªå¸ƒå±€æ–‡ä»¶")
        
        # åˆ†ææ‰€æœ‰å¸ƒå±€æ–‡ä»¶
        for i, json_file in enumerate(json_files):
            scene_name = json_file.stem
            stats['scenes'].append(scene_name)
            
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                
                scene_objects = len(data)
                stats['total_objects'] += scene_objects
                
                # ç»Ÿè®¡å¯¹è±¡ç±»å‹
                for key in data.keys():
                    obj_type = key.split('|')[0]
                    stats['unique_object_types'].add(obj_type)
                
                # ä¿å­˜å‰10ä¸ªåœºæ™¯ä½œä¸ºæ ·æœ¬
                if i < 10:
                    stats['sample_scenes'].append({
                        'name': scene_name,
                        'objects': scene_objects,
                        'object_types': list(set(key.split('|')[0] for key in data.keys()))
                    })
                    
            except Exception as e:
                print(f"   âš ï¸  è¯»å– {json_file.name} å¤±è´¥: {e}")
    
    # åˆ†æPDDLé—®é¢˜æ–‡ä»¶
    pddl_dir = alfworld_dir / "alfworld/alfworld/gen/ff_planner/samples"
    if pddl_dir.exists():
        pddl_files = list(pddl_dir.glob("problem_*.pddl"))
        stats['pddl_files'] = len(pddl_files)
        print(f"ğŸ“ æ‰¾åˆ° {len(pddl_files)} ä¸ªPDDLé—®é¢˜æ–‡ä»¶")
    
    # åˆ†æPDDLåŸŸæ–‡ä»¶
    domain_dir = alfworld_dir / "alfworld/alfworld/gen/planner/domains"
    if domain_dir.exists():
        domain_files = list(domain_dir.glob("*_domain.pddl"))
        stats['domain_files'] = len(domain_files)
        print(f"ğŸ“ æ‰¾åˆ° {len(domain_files)} ä¸ªPDDLåŸŸæ–‡ä»¶")
    
    # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
    stats['unique_object_types'] = list(stats['unique_object_types'])
    
    return stats


def analyze_textworld_scale():
    """åˆ†æTextWorldæ•°æ®é›†è§„æ¨¡"""
    print("\nğŸ” åˆ†æTextWorldæ•°æ®é›†è§„æ¨¡...")
    
    data_dir = Path(__file__).parent.parent
    textworld_dir = data_dir / "benchmarks/textworld"
    
    stats = {
        'available': False,
        'game_files': 0,
        'benchmark_games': 0,
        'sample_games': []
    }
    
    if not textworld_dir.exists():
        print("âŒ TextWorldç›®å½•ä¸å­˜åœ¨")
        return stats
    
    stats['available'] = True
    
    # æŸ¥æ‰¾æ¸¸æˆæ–‡ä»¶
    game_files = []
    for ext in ['*.json', '*.z8', '*.ulx']:
        game_files.extend(textworld_dir.rglob(ext))
    
    stats['game_files'] = len(game_files)
    print(f"ğŸ“ æ‰¾åˆ° {len(game_files)} ä¸ªæ¸¸æˆæ–‡ä»¶")
    
    # æŸ¥æ‰¾benchmarkæ–‡ä»¶
    benchmark_file = textworld_dir / "TextWorld/benchmark/games.json"
    if benchmark_file.exists():
        try:
            with open(benchmark_file, 'r') as f:
                benchmark_data = json.load(f)
            
            if isinstance(benchmark_data, list):
                stats['benchmark_games'] = len(benchmark_data)
                stats['sample_games'] = benchmark_data[:5]  # å‰5ä¸ªä½œä¸ºæ ·æœ¬
            elif isinstance(benchmark_data, dict):
                stats['benchmark_games'] = len(benchmark_data)
                stats['sample_games'] = list(benchmark_data.items())[:5]
                
            print(f"ğŸ“ æ‰¾åˆ° {stats['benchmark_games']} ä¸ªbenchmarkæ¸¸æˆ")
            
        except Exception as e:
            print(f"   âš ï¸  è¯»å–benchmarkæ–‡ä»¶å¤±è´¥: {e}")
    
    return stats


def generate_scale_report():
    """ç”Ÿæˆè§„æ¨¡æŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆæ•°æ®é›†è§„æ¨¡æŠ¥å‘Š...")
    
    alfworld_stats = analyze_alfworld_scale()
    textworld_stats = analyze_textworld_scale()
    
    report = {
        'alfworld': alfworld_stats,
        'textworld': textworld_stats,
        'summary': {
            'total_scenes': alfworld_stats.get('layout_files', 0),
            'total_objects': alfworld_stats.get('total_objects', 0),
            'unique_object_types': len(alfworld_stats.get('unique_object_types', [])),
            'textworld_games': textworld_stats.get('benchmark_games', 0)
        }
    }
    
    # è¾“å‡ºæŠ¥å‘Š
    print("\nğŸ“‹ æ•°æ®é›†è§„æ¨¡æ€»ç»“:")
    print(f"   ALFWorld:")
    print(f"     - åœºæ™¯æ•°é‡: {report['summary']['total_scenes']}")
    print(f"     - æ€»å¯¹è±¡æ•°: {report['summary']['total_objects']}")
    print(f"     - å¯¹è±¡ç±»å‹: {report['summary']['unique_object_types']}")
    print(f"     - PDDLé—®é¢˜: {alfworld_stats.get('pddl_files', 0)}")
    print(f"     - PDDLåŸŸ: {alfworld_stats.get('domain_files', 0)}")
    
    print(f"   TextWorld:")
    print(f"     - å¯ç”¨: {textworld_stats['available']}")
    print(f"     - æ¸¸æˆæ–‡ä»¶: {textworld_stats['game_files']}")
    print(f"     - Benchmarkæ¸¸æˆ: {textworld_stats['benchmark_games']}")
    
    # æ˜¾ç¤ºæ ·æœ¬åœºæ™¯
    if alfworld_stats.get('sample_scenes'):
        print(f"\nğŸ¯ ALFWorldæ ·æœ¬åœºæ™¯ (å‰10ä¸ª):")
        for i, scene in enumerate(alfworld_stats['sample_scenes']):
            print(f"     {i+1:2d}. {scene['name']}: {scene['objects']} å¯¹è±¡")
            print(f"         ç±»å‹: {', '.join(scene['object_types'])}")
    
    # æ˜¾ç¤ºå¯¹è±¡ç±»å‹ç»Ÿè®¡
    if alfworld_stats.get('unique_object_types'):
        print(f"\nğŸ·ï¸  ALFWorldå¯¹è±¡ç±»å‹ç»Ÿè®¡:")
        for obj_type in sorted(alfworld_stats['unique_object_types']):
            print(f"     - {obj_type}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(__file__).parent / "dataset_scale_report.json"
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è§„æ¨¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return report


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†ææ•°æ®é›†è§„æ¨¡\n")
    
    report = generate_scale_report()
    
    print("\nğŸ‰ æ•°æ®é›†è§„æ¨¡åˆ†æå®Œæˆ!")
    
    return report


if __name__ == "__main__":
    main()
