#!/usr/bin/env python3
"""
æŒ‰åœºæ™¯åˆ†å‰²çš„çŸ¥è¯†å›¾è°±æ„å»ºå™¨
ä¸ºæ¯ä¸ªåœºæ™¯åˆ›å»ºç‹¬ç«‹çš„çŸ¥è¯†å›¾è°±æ–‡ä»¶
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from state_kg_builder import StateKGBuilder, GameEntity, GameAction, StateTransition


def build_separated_alfworld_kgs(max_scenes: int = 10) -> Dict[str, Any]:
    """æ„å»ºæŒ‰åœºæ™¯åˆ†å‰²çš„ALFWorldçŸ¥è¯†å›¾è°±"""
    print(f"ğŸ—ï¸ æ„å»ºæŒ‰åœºæ™¯åˆ†å‰²çš„ALFWorldçŸ¥è¯†å›¾è°± (æœ€å¤š {max_scenes} ä¸ªåœºæ™¯)...")
    
    data_dir = Path(__file__).parent.parent
    alfworld_dir = data_dir / "benchmarks/alfworld/alfworld/alfworld/gen/layouts"
    
    if not alfworld_dir.exists():
        print("âŒ ALFWorldç›®å½•ä¸å­˜åœ¨")
        return {}
    
    # è·å–å¸ƒå±€æ–‡ä»¶
    json_files = list(alfworld_dir.glob("*-openable.json"))  # ä¼˜å…ˆå¤„ç†å¯æ‰“å¼€çš„åœºæ™¯
    if not json_files:
        json_files = list(alfworld_dir.glob("*.json"))
    
    json_files = json_files[:max_scenes]
    print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªåœºæ™¯æ–‡ä»¶")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = data_dir / "knowledge_graphs/scenes"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    scene_results = {}
    processed_scenes = 0
    
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                scene_data = json.load(f)
            
            # è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„æ–‡ä»¶
            if not isinstance(scene_data, dict):
                continue
            
            scene_name = json_file.stem
            print(f"   å¤„ç†åœºæ™¯: {scene_name}")
            
            # ä¸ºæ¯ä¸ªåœºæ™¯åˆ›å»ºç‹¬ç«‹çš„çŸ¥è¯†å›¾è°±æ„å»ºå™¨
            kg_builder = StateKGBuilder()
            
            # åˆ›å»ºåœºæ™¯çŸ¥è¯†å›¾è°±
            result = kg_builder.create_alfworld_scene_kg(scene_data, scene_name)
            
            # å¯¼å‡ºå•ä¸ªåœºæ™¯çš„çŸ¥è¯†å›¾è°±
            scene_json_file = output_dir / f"{scene_name}_kg.json"
            scene_graphml_file = output_dir / f"{scene_name}_kg.graphml"
            
            builder = kg_builder.get_builder()
            builder.export_to_json(str(scene_json_file))
            builder.export_to_graphml(str(scene_graphml_file))
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = builder.get_statistics()
            
            scene_results[scene_name] = {
                'file_path': str(scene_json_file),
                'entities': result['entities'],
                'actions': result['actions'],
                'transitions': result['transitions'],
                'total_nodes': stats['total_nodes'],
                'total_edges': stats['total_edges'],
                'node_types': stats['node_types'],
                'edge_types': stats['edge_types']
            }
            
            print(f"     âœ… èŠ‚ç‚¹: {stats['total_nodes']}, è¾¹: {stats['total_edges']}")
            print(f"     ğŸ’¾ ä¿å­˜åˆ°: {scene_json_file.name}")
            
            processed_scenes += 1
            
        except Exception as e:
            print(f"     âŒ å¤„ç† {json_file.name} å¤±è´¥: {e}")
            continue
    
    print(f"âœ… æˆåŠŸå¤„ç† {processed_scenes} ä¸ªåœºæ™¯")
    print(f"ğŸ“ åœºæ™¯æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    
    # ä¿å­˜åœºæ™¯æ±‡æ€»ä¿¡æ¯
    summary_file = output_dir / "scenes_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_scenes': processed_scenes,
            'output_directory': str(output_dir),
            'scenes': scene_results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š åœºæ™¯æ±‡æ€»ä¿å­˜åˆ°: {summary_file}")
    
    return scene_results


def create_scene_index():
    """åˆ›å»ºåœºæ™¯ç´¢å¼•æ–‡ä»¶"""
    print("ğŸ“‹ åˆ›å»ºåœºæ™¯ç´¢å¼•...")
    
    data_dir = Path(__file__).parent.parent
    scenes_dir = data_dir / "knowledge_graphs/scenes"
    
    if not scenes_dir.exists():
        print("âŒ åœºæ™¯ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰åœºæ™¯æ–‡ä»¶
    scene_files = list(scenes_dir.glob("*_kg.json"))
    
    index_data = {
        'total_scenes': len(scene_files),
        'created_at': str(Path(__file__).stat().st_mtime),
        'scenes': []
    }
    
    for scene_file in scene_files:
        scene_name = scene_file.stem.replace('_kg', '')
        
        try:
            with open(scene_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            nodes = data.get('nodes', [])
            edges = data.get('edges', [])
            
            # åˆ†æåœºæ™¯å†…å®¹
            entities = [n for n in nodes if n['type'] == 'entity' and n['attributes'].get('entity_type') != 'scene']
            actions = [n for n in nodes if n['type'] == 'action']
            states = [n for n in nodes if n['type'] == 'state']
            
            scene_info = {
                'name': scene_name,
                'file': scene_file.name,
                'stats': {
                    'total_nodes': len(nodes),
                    'total_edges': len(edges),
                    'entities': len(entities),
                    'actions': len(actions),
                    'states': len(states)
                },
                'entity_types': list(set(e['attributes'].get('entity_type', 'unknown') for e in entities))
            }
            
            index_data['scenes'].append(scene_info)
            
        except Exception as e:
            print(f"   âš ï¸  åˆ†æ {scene_file.name} å¤±è´¥: {e}")
    
    # æŒ‰åœºæ™¯åæ’åº
    index_data['scenes'].sort(key=lambda x: x['name'])
    
    # ä¿å­˜ç´¢å¼•
    index_file = scenes_dir / "scene_index.json"
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… åœºæ™¯ç´¢å¼•ä¿å­˜åˆ°: {index_file}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š åœºæ™¯ç»Ÿè®¡:")
    print(f"   - æ€»åœºæ™¯æ•°: {index_data['total_scenes']}")
    
    if index_data['scenes']:
        total_nodes = sum(s['stats']['total_nodes'] for s in index_data['scenes'])
        total_edges = sum(s['stats']['total_edges'] for s in index_data['scenes'])
        total_entities = sum(s['stats']['entities'] for s in index_data['scenes'])
        
        print(f"   - æ€»èŠ‚ç‚¹æ•°: {total_nodes}")
        print(f"   - æ€»è¾¹æ•°: {total_edges}")
        print(f"   - æ€»å®ä½“æ•°: {total_entities}")
        
        # æ˜¾ç¤ºå‰5ä¸ªåœºæ™¯
        print(f"\nğŸ¯ åœºæ™¯ç¤ºä¾‹ (å‰5ä¸ª):")
        for i, scene in enumerate(index_data['scenes'][:5]):
            print(f"   {i+1}. {scene['name']}: {scene['stats']['entities']} å®ä½“, {scene['stats']['actions']} åŠ¨ä½œ")
    
    return index_data


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ„å»ºæŒ‰åœºæ™¯åˆ†å‰²çš„çŸ¥è¯†å›¾è°±\n")
    
    # æ„å»ºåˆ†å‰²çš„çŸ¥è¯†å›¾è°±
    scene_results = build_separated_alfworld_kgs(max_scenes=10)
    
    if scene_results:
        # åˆ›å»ºåœºæ™¯ç´¢å¼•
        index_data = create_scene_index()
        
        print(f"\nğŸ‰ æŒ‰åœºæ™¯åˆ†å‰²çš„çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ!")
        print(f"   - å¤„ç†åœºæ™¯æ•°: {len(scene_results)}")
        print(f"   - è¾“å‡ºç›®å½•: data/knowledge_graphs/scenes/")
        print(f"   - ç´¢å¼•æ–‡ä»¶: scene_index.json")
        
        print(f"\nğŸ“ æ–‡ä»¶ç»“æ„:")
        print(f"   data/knowledge_graphs/")
        print(f"   â”œâ”€â”€ scenes/")
        print(f"   â”‚   â”œâ”€â”€ scene_index.json          # åœºæ™¯ç´¢å¼•")
        print(f"   â”‚   â”œâ”€â”€ scenes_summary.json       # åœºæ™¯æ±‡æ€»")
        print(f"   â”‚   â”œâ”€â”€ FloorPlan228-openable_kg.json")
        print(f"   â”‚   â”œâ”€â”€ FloorPlan228-openable_kg.graphml")
        print(f"   â”‚   â””â”€â”€ ... (å…¶ä»–åœºæ™¯æ–‡ä»¶)")
        print(f"   â””â”€â”€ extracted/")
        print(f"       â””â”€â”€ ... (åˆå¹¶çš„çŸ¥è¯†å›¾è°±æ–‡ä»¶)")
    
    else:
        print("âŒ æœªèƒ½æ„å»ºä»»ä½•åœºæ™¯çŸ¥è¯†å›¾è°±")


if __name__ == "__main__":
    main()
