# KGRL å®éªŒæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨KGRLæ¡†æ¶è®¾è®¡ã€è¿è¡Œå’Œåˆ†æå®éªŒã€‚

## ğŸ§ª å®éªŒç±»å‹

### 1. åŸºçº¿å¯¹æ¯”å®éªŒ
æ¯”è¾ƒä¸åŒæ™ºèƒ½ä½“çš„æ€§èƒ½ï¼š

```bash
# è¿è¡ŒåŸºçº¿å¯¹æ¯”
python scripts/evaluate/run_comparison.py \
    --config configs/experiments/baseline_comparison.yaml \
    --output experiments/results/baseline_comparison
```

### 2. æ¶ˆèç ”ç©¶
ç³»ç»Ÿæ€§åœ°åˆ†æå„ç»„ä»¶çš„è´¡çŒ®ï¼š

```bash
# è¿è¡Œæ¶ˆèç ”ç©¶
python scripts/evaluate/run_ablation.py \
    --config configs/experiments/ablation_study.yaml \
    --output experiments/results/ablation_study
```

### 3. è¶…å‚æ•°è°ƒä¼˜
ä¼˜åŒ–æ¨¡å‹è¶…å‚æ•°ï¼š

```bash
# è¿è¡Œè¶…å‚æ•°æœç´¢
python scripts/optimize/hyperparameter_search.py \
    --config configs/experiments/hyperparameter_tuning.yaml \
    --method grid_search  # grid_search, random_search, bayesian
```

### 4. å¯æ‰©å±•æ€§æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿåœ¨ä¸åŒè§„æ¨¡ä¸‹çš„æ€§èƒ½ï¼š

```bash
# è¿è¡Œå¯æ‰©å±•æ€§æµ‹è¯•
python scripts/evaluate/scalability_test.py \
    --config configs/experiments/scalability_test.yaml \
    --scales small,medium,large,xlarge
```

## ğŸ“Š å®éªŒè®¾è®¡

### åŸºæœ¬å®éªŒé…ç½®
```yaml
# configs/experiments/my_experiment.yaml
experiment_name: "my_experiment"
experiment_type: "comparison"
description: "æˆ‘çš„è‡ªå®šä¹‰å®éªŒ"

# å®éªŒå‚æ•°
parameters:
  num_episodes: 100
  num_runs: 5
  max_steps_per_episode: 30
  random_seed: 42

# æ™ºèƒ½ä½“é…ç½®
agents:
  - name: "baseline"
    config: "configs/agents/llm_baseline.yaml"
  - name: "enhanced"
    config: "configs/agents/unified_agent.yaml"

# ç¯å¢ƒé…ç½®
environments:
  - "configs/environments/textworld_easy.yaml"
  - "configs/environments/textworld_medium.yaml"

# è¯„ä¼°æŒ‡æ ‡
metrics:
  - "success_rate"
  - "avg_steps"
  - "decision_time"
  - "knowledge_utilization"
  - "memory_efficiency"

# ç»Ÿè®¡åˆ†æ
statistical_analysis:
  significance_tests: ["t_test", "mann_whitney"]
  effect_size: ["cohen_d", "cliff_delta"]
  confidence_level: 0.95
  multiple_comparison_correction: "bonferroni"
```

### æ¶ˆèç ”ç©¶è®¾è®¡
```yaml
# configs/experiments/detailed_ablation.yaml
experiment_name: "detailed_ablation"
experiment_type: "ablation"

# åŸºç¡€é…ç½®
base_config: "configs/agents/unified_agent.yaml"

# æ¶ˆèå˜é‡ï¼ˆå…¨å› å­è®¾è®¡ï¼‰
ablation_variables:
  - name: "knowledge_graph"
    values: [true, false]
    config_path: "capabilities.use_knowledge_graph"
    
  - name: "memory_system"
    values: [true, false]
    config_path: "capabilities.use_memory"
    
  - name: "reasoning_type"
    values: ["none", "react", "chain_of_thought"]
    config_path: "reasoning.strategy"
    
  - name: "kg_retrieval_method"
    values: ["keyword", "semantic", "hybrid"]
    config_path: "knowledge_graph.retrieval_method"
    condition: "knowledge_graph == true"  # æ¡ä»¶æ¶ˆè

# å®éªŒè®¾ç½®
training:
  num_episodes: 50
  num_runs: 3
  early_stopping:
    enabled: true
    patience: 10
    min_improvement: 0.01

# åˆ†æè®¾ç½®
analysis:
  component_importance: true
  interaction_effects: true
  learning_curves: true
  statistical_power: 0.8
```

## ğŸš€ è¿è¡Œå®éªŒ

### å•ä¸ªå®éªŒ
```bash
# åŸºæœ¬è¿è¡Œ
python scripts/train/train_unified.py \
    --config configs/agents/my_agent.yaml \
    --num-episodes 100 \
    --output experiments/results/single_run

# å¸¦è¯¦ç»†æ—¥å¿—
python scripts/train/train_unified.py \
    --config configs/agents/my_agent.yaml \
    --num-episodes 100 \
    --log-level DEBUG \
    --save-checkpoints \
    --output experiments/results/detailed_run
```

### æ‰¹é‡å®éªŒ
```bash
# è¿è¡Œå¤šä¸ªé…ç½®
python scripts/evaluate/batch_experiments.py \
    --configs configs/agents/llm_baseline.yaml configs/agents/unified_agent.yaml \
    --num-runs 5 \
    --parallel 2 \
    --output experiments/results/batch_run

# ä½¿ç”¨å®éªŒé…ç½®æ–‡ä»¶
python scripts/evaluate/run_experiment.py \
    --experiment-config configs/experiments/my_experiment.yaml \
    --parallel 4 \
    --resume-from experiments/results/my_experiment  # æ–­ç‚¹ç»­è·‘
```

### åˆ†å¸ƒå¼å®éªŒ
```bash
# ä½¿ç”¨å¤šGPU
python scripts/train/distributed_training.py \
    --config configs/agents/rl_kg_agent.yaml \
    --gpus 0,1,2,3 \
    --strategy ddp

# ä½¿ç”¨é›†ç¾¤
python scripts/train/cluster_training.py \
    --config configs/experiments/large_scale_experiment.yaml \
    --nodes 4 \
    --tasks-per-node 8
```

## ğŸ“ˆ å®éªŒç›‘æ§

### å®æ—¶ç›‘æ§
```bash
# å¯åŠ¨ç›‘æ§æœåŠ¡
python scripts/monitoring/start_monitor.py \
    --experiment-dir experiments/results/my_experiment \
    --port 8080

# æŸ¥çœ‹å®æ—¶æŒ‡æ ‡
python scripts/monitoring/live_metrics.py \
    --experiment my_experiment \
    --refresh-interval 10
```

### Weights & Biasesé›†æˆ
```yaml
# åœ¨é…ç½®ä¸­å¯ç”¨W&B
logging:
  wandb:
    enabled: true
    project: "kgrl_experiments"
    entity: "research_team"
    tags: ["ablation", "textworld"]
    
    # è®°å½•çš„æŒ‡æ ‡
    metrics:
      - "episode_reward"
      - "success_rate"
      - "knowledge_queries"
      - "decision_time"
    
    # è®°å½•çš„åª’ä½“
    media:
      - "learning_curves"
      - "attention_maps"
      - "knowledge_graph_evolution"
```

### TensorBoardé›†æˆ
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir experiments/results/my_experiment/tensorboard

# è®°å½•è‡ªå®šä¹‰æŒ‡æ ‡
python scripts/utils/log_to_tensorboard.py \
    --experiment-dir experiments/results/my_experiment \
    --metrics success_rate,avg_steps,decision_time
```

## ğŸ“Š ç»“æœåˆ†æ

### åŸºæœ¬ç»Ÿè®¡åˆ†æ
```bash
# ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
python scripts/analysis/statistical_analysis.py \
    --results experiments/results/baseline_comparison \
    --output experiments/analysis/statistical_report.html

# è®¡ç®—æ•ˆåº”å¤§å°
python scripts/analysis/effect_size_analysis.py \
    --baseline experiments/results/llm_baseline \
    --treatment experiments/results/unified_agent \
    --metrics success_rate,avg_steps
```

### å¯è§†åŒ–åˆ†æ
```bash
# ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾
python scripts/visualization/performance_plots.py \
    --results experiments/results/baseline_comparison \
    --output experiments/plots/performance_comparison.png

# ç”Ÿæˆå­¦ä¹ æ›²çº¿
python scripts/visualization/learning_curves.py \
    --results experiments/results/training_logs \
    --smooth-window 10 \
    --output experiments/plots/learning_curves.png

# ç”Ÿæˆæ¶ˆèç ”ç©¶çƒ­åŠ›å›¾
python scripts/visualization/ablation_heatmap.py \
    --results experiments/results/ablation_study \
    --metric success_rate \
    --output experiments/plots/ablation_heatmap.png
```

### é«˜çº§åˆ†æ
```python
# è‡ªå®šä¹‰åˆ†æè„šæœ¬ç¤ºä¾‹
from src.analysis import ExperimentAnalyzer, StatisticalTester

# åŠ è½½å®éªŒç»“æœ
analyzer = ExperimentAnalyzer("experiments/results/my_experiment")

# åŸºæœ¬ç»Ÿè®¡
stats = analyzer.compute_basic_statistics()
print(f"å¹³å‡æˆåŠŸç‡: {stats['success_rate']['mean']:.3f} Â± {stats['success_rate']['std']:.3f}")

# æ˜¾è‘—æ€§æµ‹è¯•
tester = StatisticalTester()
p_value = tester.compare_groups(
    group1=analyzer.get_metric("baseline", "success_rate"),
    group2=analyzer.get_metric("enhanced", "success_rate"),
    test="mann_whitney"
)
print(f"æ˜¾è‘—æ€§æ£€éªŒ p-value: {p_value:.4f}")

# æ•ˆåº”å¤§å°
effect_size = tester.compute_effect_size(
    group1=analyzer.get_metric("baseline", "success_rate"),
    group2=analyzer.get_metric("enhanced", "success_rate"),
    method="cohen_d"
)
print(f"Cohen's d: {effect_size:.3f}")
```

## ğŸ” å®éªŒè°ƒè¯•

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è°ƒè¯•æ¨¡å¼
python scripts/train/train_unified.py \
    --config configs/agents/my_agent.yaml \
    --debug \
    --save-states \
    --num-episodes 5

# è¯¦ç»†è·Ÿè¸ª
python scripts/train/train_unified.py \
    --config configs/agents/my_agent.yaml \
    --trace-execution \
    --profile-performance \
    --output experiments/debug/trace_run
```

### é”™è¯¯è¯Šæ–­
```bash
# éªŒè¯é…ç½®
python scripts/utils/validate_experiment.py \
    --config configs/experiments/my_experiment.yaml

# æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
python scripts/utils/check_results.py \
    --results-dir experiments/results/my_experiment \
    --fix-missing-data

# æ€§èƒ½åˆ†æ
python scripts/utils/performance_analysis.py \
    --results experiments/results/my_experiment \
    --identify-bottlenecks
```

## ğŸ“‹ å®éªŒæœ€ä½³å®è·µ

### 1. å®éªŒè®¾è®¡åŸåˆ™
- **æ§åˆ¶å˜é‡**: æ¯æ¬¡åªæ”¹å˜ä¸€ä¸ªå˜é‡
- **éšæœºåŒ–**: ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
- **é‡å¤å®éªŒ**: å¤šæ¬¡è¿è¡Œç¡®ä¿ç»“æœå¯é 
- **ç»Ÿè®¡åŠŸæ•ˆ**: ç¡®ä¿æ ·æœ¬é‡è¶³å¤Ÿ

### 2. ç»“æœè®°å½•
```yaml
# å®Œæ•´çš„å®éªŒè®°å½•
experiment_metadata:
  date: "2024-01-01"
  researcher: "ç ”ç©¶å‘˜å§“å"
  hypothesis: "ç»Ÿä¸€æ™ºèƒ½ä½“æ¯”åŸºçº¿æ™ºèƒ½ä½“æ€§èƒ½æ›´å¥½"
  
  environment:
    python_version: "3.9.7"
    pytorch_version: "1.12.0"
    cuda_version: "11.6"
    hardware: "NVIDIA RTX 3080"
    
  data_sources:
    training_data: "data/textworld_games_v1.2"
    knowledge_base: "data/kg/cooking_domain.json"
    
  preprocessing:
    text_normalization: true
    knowledge_filtering: "confidence > 0.5"
```

### 3. å¯é‡ç°æ€§æ£€æŸ¥æ¸…å•
- [ ] å›ºå®šéšæœºç§å­
- [ ] è®°å½•æ‰€æœ‰ä¾èµ–ç‰ˆæœ¬
- [ ] ä¿å­˜å®Œæ•´é…ç½®æ–‡ä»¶
- [ ] è®°å½•æ•°æ®é¢„å¤„ç†æ­¥éª¤
- [ ] ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
- [ ] è®°å½•ç¡¬ä»¶ç¯å¢ƒä¿¡æ¯

### 4. ç»“æœéªŒè¯
```bash
# é‡ç°æ€§æµ‹è¯•
python scripts/validation/reproduce_results.py \
    --original-results experiments/results/published_results \
    --config configs/experiments/reproduction_test.yaml \
    --tolerance 0.05

# äº¤å‰éªŒè¯
python scripts/validation/cross_validation.py \
    --config configs/agents/my_agent.yaml \
    --folds 5 \
    --stratified
```

## ğŸ“Š å®éªŒæŠ¥å‘Šç”Ÿæˆ

### è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ
```bash
# ç”Ÿæˆå®Œæ•´å®éªŒæŠ¥å‘Š
python scripts/reporting/generate_report.py \
    --experiment experiments/results/my_experiment \
    --template templates/experiment_report.html \
    --output experiments/reports/my_experiment_report.html

# ç”ŸæˆLaTeXè¡¨æ ¼
python scripts/reporting/generate_latex_tables.py \
    --results experiments/results/baseline_comparison \
    --output experiments/reports/tables.tex

# ç”Ÿæˆè®ºæ–‡å›¾è¡¨
python scripts/reporting/generate_paper_figures.py \
    --results experiments/results/ablation_study \
    --style ieee \
    --output experiments/reports/figures/
```

### æŠ¥å‘Šæ¨¡æ¿
```html
<!-- templates/experiment_report.html -->
<!DOCTYPE html>
<html>
<head>
    <title>KGRLå®éªŒæŠ¥å‘Š: {{experiment_name}}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .metric { background: #f5f5f5; padding: 10px; margin: 10px 0; }
        .significant { color: #d32f2f; font-weight: bold; }
    </style>
</head>
<body>
    <h1>å®éªŒæŠ¥å‘Š: {{experiment_name}}</h1>
    
    <h2>å®éªŒæ¦‚è¿°</h2>
    <p>å®éªŒæ—¥æœŸ: {{date}}</p>
    <p>å®éªŒæè¿°: {{description}}</p>
    
    <h2>ä¸»è¦ç»“æœ</h2>
    {% for agent in agents %}
    <div class="metric">
        <h3>{{agent.name}}</h3>
        <p>æˆåŠŸç‡: {{agent.success_rate}} Â± {{agent.success_rate_std}}</p>
        <p>å¹³å‡æ­¥æ•°: {{agent.avg_steps}} Â± {{agent.avg_steps_std}}</p>
    </div>
    {% endfor %}
    
    <h2>ç»Ÿè®¡åˆ†æ</h2>
    {% for comparison in statistical_comparisons %}
    <p class="{% if comparison.significant %}significant{% endif %}">
        {{comparison.name}}: p = {{comparison.p_value}}
        {% if comparison.significant %}(æ˜¾è‘—){% endif %}
    </p>
    {% endfor %}
    
    <h2>å¯è§†åŒ–ç»“æœ</h2>
    <img src="{{performance_plot}}" alt="æ€§èƒ½å¯¹æ¯”å›¾">
    <img src="{{learning_curves}}" alt="å­¦ä¹ æ›²çº¿">
</body>
</html>
```

## ğŸ¯ é«˜çº§å®éªŒæŠ€å·§

### 1. è‡ªé€‚åº”å®éªŒ
```python
# åŸºäºä¸­é—´ç»“æœè°ƒæ•´å®éªŒå‚æ•°
from src.experiments import AdaptiveExperiment

experiment = AdaptiveExperiment("adaptive_tuning")

# å®šä¹‰é€‚åº”ç­–ç•¥
experiment.add_adaptation_rule(
    condition="success_rate < 0.3 after 20 episodes",
    action="increase learning_rate by 50%"
)

experiment.add_adaptation_rule(
    condition="decision_time > 1.0 seconds",
    action="reduce max_retrieved_docs to 3"
)

# è¿è¡Œè‡ªé€‚åº”å®éªŒ
results = experiment.run()
```

### 2. å¤šç›®æ ‡ä¼˜åŒ–
```yaml
# å¤šç›®æ ‡ä¼˜åŒ–é…ç½®
optimization:
  objectives:
    - name: "success_rate"
      direction: "maximize"
      weight: 0.6
      
    - name: "decision_time"
      direction: "minimize"
      weight: 0.3
      
    - name: "knowledge_utilization"
      direction: "maximize"
      weight: 0.1
      
  method: "nsga2"  # éæ”¯é…æ’åºé—ä¼ ç®—æ³•
  population_size: 50
  generations: 100
```

### 3. åœ¨çº¿å­¦ä¹ å®éªŒ
```bash
# åœ¨çº¿å­¦ä¹ æ¨¡å¼
python scripts/train/online_learning.py \
    --config configs/agents/online_agent.yaml \
    --stream-data data/streaming_episodes.jsonl \
    --adaptation-rate 0.01 \
    --evaluation-interval 100
```

---

**æç¤ºï¼š** å®éªŒè®¾è®¡æ˜¯ç§‘å­¦ç ”ç©¶çš„æ ¸å¿ƒã€‚èŠ±æ—¶é—´ä»”ç»†è®¾è®¡å®éªŒæ¯”åŒ†å¿™è¿è¡Œå¤§é‡å®éªŒæ›´æœ‰ä»·å€¼ã€‚

**æœ€åæ›´æ–°ï¼š** 2024-01-01  
**ç‰ˆæœ¬ï¼š** 1.0.0  
**ç»´æŠ¤è€…ï¼š** KGRLç ”ç©¶å›¢é˜Ÿ
