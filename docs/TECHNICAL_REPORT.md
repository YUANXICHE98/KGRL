# KGRLé¡¹ç›®æŠ€æœ¯æŠ¥å‘Š

## é¡¹ç›®æ¦‚è¿°

KGRL (Knowledge Graph Reinforcement Learning) æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºæ–‡æœ¬å†’é™©æ¸¸æˆç¯å¢ƒä¸­çš„æŒ‡ä»¤è·Ÿéšä»»åŠ¡ã€‚

## æ ¸å¿ƒæ¶æ„

### 1. ç³»ç»Ÿç»„ä»¶å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Environment   â”‚    â”‚  Knowledge Graph â”‚    â”‚     Agent       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ TextWorld   â”‚ â”‚    â”‚ â”‚ KG Builder  â”‚ â”‚    â”‚ â”‚ Baseline    â”‚ â”‚
â”‚ â”‚ (Simulated) â”‚ â”‚    â”‚ â”‚             â”‚ â”‚    â”‚ â”‚ LLM Agent   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ KG Retrieverâ”‚ â”‚    â”‚ â”‚ RAG Agent   â”‚ â”‚
â”‚ â”‚ ALFWorld    â”‚ â”‚    â”‚ â”‚             â”‚ â”‚    â”‚ â”‚ (Future)    â”‚ â”‚
â”‚ â”‚ (Optional)  â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           
```

### 2. æ•°æ®æµå‘

```
è§‚å¯Ÿæ–‡æœ¬ â†’ Agent â†’ åŠ¨ä½œé€‰æ‹© â†’ ç¯å¢ƒæ‰§è¡Œ â†’ æ–°è§‚å¯Ÿ + å¥–åŠ±
    â†‘                â†“
çŸ¥è¯†å›¾è°± â† æ£€ç´¢æŸ¥è¯¢ â† ReActæ¨ç†æ¡†æ¶
```

## è¯¦ç»†ç»„ä»¶åˆ†æ

### ç¯å¢ƒå±‚ (Environment Layer)

**æ ¸å¿ƒæ¥å£**: `BaseEnvironment`
```python
class BaseEnvironment:
    def reset() -> str                    # é‡ç½®ç¯å¢ƒï¼Œè¿”å›åˆå§‹è§‚å¯Ÿ
    def step(action: str) -> Tuple        # æ‰§è¡ŒåŠ¨ä½œï¼Œè¿”å›(obs, reward, done, info)
    def get_available_actions() -> List   # è·å–å½“å‰å¯ç”¨åŠ¨ä½œåˆ—è¡¨
```

**å®ç°ç»„ä»¶**:
- `TextWorldEnvironment`: æ¨¡æ‹ŸTextWorldç¯å¢ƒ
- `ALFWorldEnvironment`: å®¶åº­ä»»åŠ¡ç¯å¢ƒï¼ˆå¯é€‰ï¼‰

**å¯æ›¿æ¢æ€§**: 
- çœŸå®TextWorld â†” æ¨¡æ‹Ÿç¯å¢ƒ
- ä¸åŒéš¾åº¦çº§åˆ«
- ä¸åŒä»»åŠ¡ç±»å‹

### çŸ¥è¯†å›¾è°±å±‚ (Knowledge Graph Layer)

**æ ¸å¿ƒæ•°æ®ç»“æ„**:
```python
@dataclass
class KGFact:
    subject: str      # ä¸»ä½“
    predicate: str    # è°“è¯
    object: str       # å®¢ä½“
    confidence: float # ç½®ä¿¡åº¦
```

**ç»„ä»¶åŠŸèƒ½**:

1. **KnowledgeGraphBuilder**
   - äº‹å®å­˜å‚¨: JSONæ ¼å¼æŒä¹…åŒ–
   - å›¾æ„å»º: NetworkXå›¾ç»“æ„
   - å…³ç³»æ¨ç†: åŸºäºè§„åˆ™çš„æ¨ç†

2. **KnowledgeGraphRetriever**
   - å…³é”®è¯æ£€ç´¢: ç²¾ç¡®åŒ¹é…
   - è¯­ä¹‰æ£€ç´¢: TF-IDF + ä½™å¼¦ç›¸ä¼¼åº¦
   - å›¾éå†: BFS/DFSè·¯å¾„æŸ¥æ‰¾

**æ£€ç´¢æ¥å£**:
```python
def retrieve_by_keywords(query: str) -> List[KGFact]
def retrieve_by_similarity(query: str) -> List[KGFact]  
def retrieve_paths(start: str, end: str) -> List[Path]
```

### æ™ºèƒ½ä½“å±‚ (Agent Layer)

**åŸºç¡€æ¥å£**: `BaseAgent`
```python
class BaseAgent:
    def act(observation: str, actions: List[str]) -> str
    def reset() -> None
    def get_stats() -> Dict
```

**å®ç°ç»„ä»¶**:

1. **BaselineAgent**
   - LLMè°ƒç”¨: OpenAI GPT-4o API
   - Promptå·¥ç¨‹: ä»»åŠ¡ç‰¹å®šæç¤ºè¯
   - åŠ¨ä½œè§£æ: æ­£åˆ™è¡¨è¾¾å¼æå–

2. **RAGAgent** (è®¡åˆ’ä¸­)
   - çŸ¥è¯†æ£€ç´¢: é›†æˆKGæ£€ç´¢å™¨
   - ReActæ¨ç†: æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯
   - ä¸Šä¸‹æ–‡èåˆ: è§‚å¯Ÿ+çŸ¥è¯†â†’å†³ç­–

### æ¨ç†æ¡†æ¶ (Reasoning Framework)

**ReActå¾ªç¯**:
```
Thought: åˆ†æå½“å‰æƒ…å†µ
Action: é€‰æ‹©æ‰§è¡ŒåŠ¨ä½œ
Observation: è·å–ç¯å¢ƒåé¦ˆ
â†’ é‡å¤ç›´åˆ°ä»»åŠ¡å®Œæˆ
```

**å®ç°ç»†èŠ‚**:
- åŠ¨ä½œæå–: `extract_action_from_*()` æ–¹æ³•æ—
- æ€è€ƒç”Ÿæˆ: ç»“æ„åŒ–promptæ¨¡æ¿
- çŸ¥è¯†èåˆ: æ£€ç´¢ç»“æœæ³¨å…¥æ¨ç†è¿‡ç¨‹

## æŠ€æœ¯æ ˆ

### æ ¸å¿ƒä¾èµ–
- **LLM API**: OpenAI GPT-4o (å¯é…ç½®base_url)
- **çŸ¥è¯†å›¾è°±**: NetworkX + è‡ªå®šä¹‰JSONå­˜å‚¨
- **æ–‡æœ¬å¤„ç†**: scikit-learn TF-IDF
- **ç¯å¢ƒæ¨¡æ‹Ÿ**: è‡ªç ”TextWorldå…¼å®¹å±‚

### é…ç½®ç³»ç»Ÿ
```python
# APIé…ç½®
OPENAI_API_KEY: str
OPENAI_BASE_URL: str = "https://vir.vimsai.com/v1"

# ç¯å¢ƒé…ç½®  
ENVIRONMENT_TYPE: str = "textworld"
DIFFICULTY: str = "easy"
MAX_EPISODE_STEPS: int = 50

# Agenté…ç½®
MODEL_NAME: str = "gpt-4o"
TEMPERATURE: float = 0.7
MAX_TOKENS: int = 150
```

## æ¶ˆèå®éªŒè®¾è®¡

### å¯æ›¿æ¢ç»„ä»¶çŸ©é˜µ

| ç»„ä»¶ç±»å‹ | åŸºçº¿ç‰ˆæœ¬ | å˜ä½“1 | å˜ä½“2 | å˜ä½“3 |
|---------|---------|-------|-------|-------|
| **ç¯å¢ƒ** | æ¨¡æ‹ŸTextWorld | çœŸå®TextWorld | ALFWorld | è‡ªå®šä¹‰ä»»åŠ¡ |
| **LLM** | GPT-4o | GPT-3.5 | Claude | æœ¬åœ°æ¨¡å‹ |
| **çŸ¥è¯†å›¾è°±** | æ‰‹å·¥æ„å»º | è‡ªåŠ¨æŠ½å– | é¢„è®­ç»ƒKG | æ— KG |
| **æ£€ç´¢æ–¹æ³•** | TF-IDF | BM25 | è¯­ä¹‰åµŒå…¥ | å›¾ç¥ç»ç½‘ç»œ |
| **æ¨ç†æ¡†æ¶** | ReAct | CoT | ç›´æ¥æ¨ç† | å¼ºåŒ–å­¦ä¹  |

### å®éªŒé…ç½®
```python
# æ¶ˆèå®éªŒé…ç½®ç¤ºä¾‹
ABLATION_CONFIGS = {
    "baseline": {
        "agent": "BaselineAgent",
        "kg_enabled": False,
        "reasoning": "direct"
    },
    "kg_only": {
        "agent": "RAGAgent", 
        "kg_enabled": True,
        "reasoning": "direct"
    },
    "react_only": {
        "agent": "BaselineAgent",
        "kg_enabled": False, 
        "reasoning": "react"
    },
    "full_system": {
        "agent": "RAGAgent",
        "kg_enabled": True,
        "reasoning": "react"
    }
}
```

## å®éªŒç»“æœä¸åˆ†æ

### å®éªŒç¯å¢ƒåŸºå‡†

**æ¨¡æ‹ŸTextWorldç¯å¢ƒè®¾è®¡**:
- **3æˆ¿é—´å›ºå®šåœºæ™¯**: Kitchen â†’ Living Room â†’ Bedroom
- **æ ‡å‡†ä»»åŠ¡**: "Find the key and open the chest in the bedroom"
- **æˆ¿é—´é…ç½®**:
  - Kitchen: åŒ…å«apple, keyï¼›å‡ºå£north
  - Living Room: åŒ…å«bookï¼›å‡ºå£south, east
  - Bedroom: åŒ…å«pillow, chestï¼›å‡ºå£west
- **çº¦æŸæ¡ä»¶**: æœ€å¤§30æ­¥ï¼Œè¶…æ—¶è§†ä¸ºå¤±è´¥

### çœŸå®å®éªŒç»“æœ

**å®éªŒè§„æ¨¡**: 12 episodes (æ¯ç§Agent 6ä¸ªepisodes)

| Agentç±»å‹ | æˆåŠŸç‡ | å¹³å‡æ­¥æ•° | å¹³å‡å¥–åŠ± | KGæŸ¥è¯¢å‘½ä¸­ç‡ | APIå“åº”æ—¶é—´ |
|-----------|--------|----------|----------|--------------|-------------|
| Baseline LLM | 50.0% (3/6) | 21.3æ­¥ | 0.250 | N/A | ~2.5s |
| RAG LLM | 0.0% (0/6) | 30.0æ­¥ | -0.783 | 98.89% | ~4.0s |

### è¯¦ç»†åˆ†æ

**Baseline Agentè¡¨ç°**:
- Episode 1,2,6: âœ… æˆåŠŸ (9,20,9æ­¥)
- Episode 3,4,5: âŒ å¤±è´¥ (30æ­¥è¶…æ—¶)
- æˆåŠŸæ¨¡å¼: å¿«é€Ÿæ‰¾åˆ°keyå¹¶åˆ°è¾¾bedroom

**RAG Agentè¡¨ç°**:
- æ‰€æœ‰6ä¸ªepisodes: âŒ å¤±è´¥ (30æ­¥è¶…æ—¶)
- KGä½¿ç”¨: 180æ¬¡æŸ¥è¯¢ï¼Œ178æ¬¡å‘½ä¸­ (98.89%å‘½ä¸­ç‡)
- é—®é¢˜: æ¨ç†è¿‡ç¨‹è¿‡äºå¤æ‚ï¼Œå¯¼è‡´å†³ç­–æ•ˆç‡ä½ä¸‹

### å…³é”®å‘ç°

1. **æŠ€æœ¯å¯è¡Œæ€§éªŒè¯**: KGæ£€ç´¢ç³»ç»Ÿå®Œå…¨å·¥ä½œï¼Œ98.89%å‘½ä¸­ç‡
2. **å¤æ‚æ€§æ‚–è®º**: çŸ¥è¯†å¢å¼ºåè€Œé™ä½äº†æ€§èƒ½
3. **æ¨ç†æ•ˆç‡é—®é¢˜**: ReActæ¡†æ¶å¯èƒ½è¿‡äºå¤æ‚
4. **Promptå·¥ç¨‹éœ€æ±‚**: éœ€è¦ä¼˜åŒ–çŸ¥è¯†èåˆç­–ç•¥

## è¯„ä¼°æŒ‡æ ‡

### æ€§èƒ½æŒ‡æ ‡
- **æˆåŠŸç‡**: ä»»åŠ¡å®Œæˆç™¾åˆ†æ¯”
- **å¹³å‡æ­¥æ•°**: å®Œæˆä»»åŠ¡æ‰€éœ€æ­¥æ•°
- **æ— æ•ˆæŒ‡ä»¤ç‡**: æ— æ•ˆåŠ¨ä½œå æ¯”
- **çŸ¥è¯†åˆ©ç”¨ç‡**: KGæ£€ç´¢å‘½ä¸­ç‡

### å®ç°ä½ç½®
- çœŸå®å®éªŒè„šæœ¬: `experiments/complete_real_experiment.py`
- RAGå®éªŒè„šæœ¬: `run_real_rag_experiment.py`
- ç»“æœåˆ†æ: `scripts/analyze_results.py`
- å¯è§†åŒ–: `src/utils/visualization.py`

### å®éªŒæ•°æ®ä½ç½®
- **çœŸå®å®éªŒæ•°æ®**: `results/real_rag_vs_baseline/data/real_experiment_results_20250829_124035.json`
- **CSVæ ¼å¼**: `results/real_rag_vs_baseline/data/real_experiment_results_20250829_124035.csv`
- **åŒ…å«å­—æ®µ**: episode_id, agent_type, success, total_steps, total_reward, kg_queries, kg_hits, api_response_timesç­‰

## æ‰©å±•æ€§è®¾è®¡

### æ–°ç¯å¢ƒæ¥å…¥
1. ç»§æ‰¿`BaseEnvironment`
2. å®ç°æ ‡å‡†æ¥å£æ–¹æ³•
3. æ³¨å†Œåˆ°ç¯å¢ƒå·¥å‚

### æ–°Agentå¼€å‘
1. ç»§æ‰¿`BaseAgent`
2. å®ç°`act()`æ–¹æ³•
3. å¯é€‰é›†æˆKGæ£€ç´¢å™¨

### æ–°çŸ¥è¯†æºé›†æˆ
1. å®ç°`KnowledgeSource`æ¥å£
2. æä¾›ç»Ÿä¸€çš„äº‹å®æå–æ–¹æ³•
3. é›†æˆåˆ°KGæ„å»ºæµç¨‹

## å®é™…è¿è¡Œç¤ºä¾‹

### å®Œæ•´ç³»ç»Ÿæ¼”ç¤º
```bash
# è¿è¡Œå®Œæ•´ç³»ç»Ÿæ¼”ç¤º
python -c "
import sys; sys.path.append('.')
from src.environments.textworld_env import TextWorldEnvironment
from src.knowledge.kg_builder import KnowledgeGraphBuilder
from src.agents.baseline_agent import BaselineAgent

# åˆ›å»ºç»„ä»¶
env = TextWorldEnvironment('demo', {'difficulty': 'easy'})
kg = KnowledgeGraphBuilder('demo_kg')
kg.add_fact('kitchen', 'contains', 'fridge')
agent = BaselineAgent('demo_agent', {'model_name': 'gpt-4o'})

# è¿è¡Œæ¸¸æˆå¾ªç¯
obs = env.reset()
action = agent.act(obs, env.get_available_actions())
new_obs, reward, done, info = env.step(action)
print(f'è§‚å¯Ÿ: {obs}')
print(f'åŠ¨ä½œ: {action}')
print(f'å¥–åŠ±: {reward}')
"
```

### è¾“å‡ºç¤ºä¾‹
```
è§‚å¯Ÿ: You are in a kitchen. There is a fridge here. Goal: Find the key and open the chest in the bedroom.
åŠ¨ä½œ: take key
å¥–åŠ±: 0.1
```

## å½“å‰çŠ¶æ€

### âœ… å·²å®Œæˆ (Week 1)
- [x] æ¨¡æ‹ŸTextWorldç¯å¢ƒ - å®Œå…¨å…¼å®¹API
- [x] åŸºç¡€çŸ¥è¯†å›¾è°±ç³»ç»Ÿ - JSONå­˜å‚¨ + NetworkX
- [x] Baseline LLM Agent - GPT-4oé›†æˆ
- [x] çœŸå®APIé›†æˆ - è‡ªå®šä¹‰base_urlæ”¯æŒ
- [x] å®Œæ•´çš„æ¸¸æˆå¾ªç¯ - è§‚å¯Ÿâ†’å†³ç­–â†’æ‰§è¡Œâ†’åé¦ˆ
- [x] çŸ¥è¯†æ£€ç´¢ç³»ç»Ÿ - TF-IDF + è¯­ä¹‰æ£€ç´¢

### ğŸ”„ è¿›è¡Œä¸­ (Week 2)
- [ ] RAG Agentå®ç° - çŸ¥è¯†å›¾è°±é›†æˆ
- [ ] ReActæ¨ç†æ¡†æ¶ - æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯
- [ ] è¯„ä¼°ç³»ç»Ÿå®Œå–„ - è‡ªåŠ¨åŒ–æµ‹è¯•

### ğŸ“‹ è®¡åˆ’ä¸­ (Week 3+)
- [ ] ALFWorldç¯å¢ƒé›†æˆ - å®¶åº­ä»»åŠ¡åœºæ™¯
- [ ] å¤šæ¨¡å‹å¯¹æ¯”å®éªŒ - GPT vs Claude vs æœ¬åœ°æ¨¡å‹
- [ ] çŸ¥è¯†å›¾è°±è‡ªåŠ¨æ„å»º - ä»æ–‡æœ¬ä¸­æŠ½å–äº‹å®
- [ ] å¼ºåŒ–å­¦ä¹ é›†æˆ - PPOè®­ç»ƒä¼˜åŒ–

## æ€§èƒ½åŸºå‡†

### å½“å‰åŸºçº¿æ€§èƒ½
```
ç¯å¢ƒ: æ¨¡æ‹ŸTextWorld (easy)
Agent: BaselineAgent + GPT-4o
ç»“æœ: 
- æˆåŠŸç‡: å¾…æµ‹è¯•
- å¹³å‡æ­¥æ•°: å¾…æµ‹è¯•  
- APIå“åº”æ—¶é—´: ~2-3ç§’
- çŸ¥è¯†æ£€ç´¢æ—¶é—´: <100ms
```

## æ•°æ®æµå‘è¯¦è§£

### å®Œæ•´æ•°æ®æµç¨‹å›¾

```
ç”¨æˆ·è¾“å…¥/ç¯å¢ƒé‡ç½®
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Environment   â”‚
â”‚   - reset()     â”‚ â†’ åˆå§‹è§‚å¯Ÿæ–‡æœ¬
â”‚   - step()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Agent       â”‚
â”‚ - act(obs,acts) â”‚ â† è§‚å¯Ÿæ–‡æœ¬ + å¯ç”¨åŠ¨ä½œåˆ—è¡¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Knowledge Graph â”‚
â”‚ - retrieve()    â”‚ â† æŸ¥è¯¢å…³é”®è¯/è¯­ä¹‰
â”‚ - build_index() â”‚ â†’ ç›¸å…³äº‹å®åˆ—è¡¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ReAct Framework â”‚
â”‚ - think()       â”‚ â† è§‚å¯Ÿ + çŸ¥è¯† + å†å²
â”‚ - act()         â”‚ â†’ ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM API       â”‚
â”‚ - chat()        â”‚ â† å®Œæ•´prompt
â”‚ - parse()       â”‚ â†’ åŠ¨ä½œå­—ç¬¦ä¸²
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Environment   â”‚
â”‚ - step(action)  â”‚ â† è§£æåçš„åŠ¨ä½œ
â”‚ - get_reward()  â”‚ â†’ (æ–°è§‚å¯Ÿ, å¥–åŠ±, å®ŒæˆçŠ¶æ€)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ¥å£è§„èŒƒ

#### 1. ç¯å¢ƒæ¥å£ (Environment Interface)
```python
class BaseEnvironment:
    def reset(self) -> str:
        """é‡ç½®ç¯å¢ƒï¼Œè¿”å›åˆå§‹è§‚å¯Ÿ"""

    def step(self, action: str) -> Tuple[str, float, bool, Dict]:
        """æ‰§è¡ŒåŠ¨ä½œï¼Œè¿”å›(è§‚å¯Ÿ, å¥–åŠ±, æ˜¯å¦å®Œæˆ, é¢å¤–ä¿¡æ¯)"""

    def get_available_actions(self) -> List[str]:
        """è·å–å½“å‰çŠ¶æ€ä¸‹çš„å¯ç”¨åŠ¨ä½œåˆ—è¡¨"""

    def render(self) -> str:
        """æ¸²æŸ“å½“å‰ç¯å¢ƒçŠ¶æ€ï¼ˆå¯é€‰ï¼‰"""
```

#### 2. çŸ¥è¯†å›¾è°±æ¥å£ (Knowledge Graph Interface)
```python
class KnowledgeGraphRetriever:
    def retrieve_by_keywords(self, query: str, max_results: int = 10) -> List[KGFact]:
        """åŸºäºå…³é”®è¯çš„ç²¾ç¡®æ£€ç´¢"""

    def retrieve_by_similarity(self, query: str, threshold: float = 0.3) -> List[KGFact]:
        """åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ¨¡ç³Šæ£€ç´¢"""

    def retrieve_paths(self, start: str, end: str, max_depth: int = 3) -> List[List[KGFact]]:
        """æ£€ç´¢ä¸¤ä¸ªå®ä½“é—´çš„å…³ç³»è·¯å¾„"""

    def build_index(self, facts: List[KGFact]) -> None:
        """æ„å»ºæ£€ç´¢ç´¢å¼•ï¼ˆTF-IDF + å›¾ç»“æ„ï¼‰"""
```

#### 3. Agentæ¥å£ (Agent Interface)
```python
class BaseAgent:
    def act(self, observation: str, available_actions: List[str]) -> str:
        """æ ¹æ®è§‚å¯Ÿå’Œå¯ç”¨åŠ¨ä½œé€‰æ‹©æœ€ä½³åŠ¨ä½œ"""

    def reset(self) -> None:
        """é‡ç½®Agentå†…éƒ¨çŠ¶æ€"""

    def get_stats(self) -> Dict[str, Any]:
        """è·å–Agentæ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""

    def update_knowledge(self, facts: List[KGFact]) -> None:
        """æ›´æ–°Agentçš„çŸ¥è¯†åº“ï¼ˆå¯é€‰ï¼‰"""
```

## å®éªŒé…ç½®è¯¦è§£

### æ¶ˆèå®éªŒé…ç½®çŸ©é˜µ

```python
EXPERIMENT_CONFIGS = {
    # åŸºçº¿å®éªŒï¼šçº¯LLMï¼Œæ— ä»»ä½•å¢å¼º
    "baseline": {
        "agent_class": "BaselineAgent",
        "model_name": "gpt-4o",
        "use_knowledge_graph": False,
        "use_react_reasoning": False,
        "temperature": 0.7,
        "max_tokens": 100
    },

    # çŸ¥è¯†å›¾è°±å¢å¼ºï¼šLLM + KGæ£€ç´¢
    "kg_enhanced": {
        "agent_class": "RAGAgent",
        "model_name": "gpt-4o",
        "use_knowledge_graph": True,
        "use_react_reasoning": False,
        "kg_retrieval_method": "tfidf",
        "max_kg_facts": 5
    },

    # ReActæ¨ç†å¢å¼ºï¼šLLM + ç»“æ„åŒ–æ¨ç†
    "react_enhanced": {
        "agent_class": "BaselineAgent",
        "model_name": "gpt-4o",
        "use_knowledge_graph": False,
        "use_react_reasoning": True,
        "max_reasoning_steps": 3
    },

    # å®Œæ•´ç³»ç»Ÿï¼šLLM + KG + ReAct
    "full_system": {
        "agent_class": "RAGAgent",
        "model_name": "gpt-4o",
        "use_knowledge_graph": True,
        "use_react_reasoning": True,
        "kg_retrieval_method": "semantic",
        "max_kg_facts": 5,
        "max_reasoning_steps": 3
    }
}
```

### ç¯å¢ƒé…ç½®å˜ä½“

```python
ENVIRONMENT_CONFIGS = {
    "easy": {
        "difficulty": "easy",
        "max_episode_steps": 20,
        "num_rooms": 3,
        "num_objects": 5
    },
    "medium": {
        "difficulty": "medium",
        "max_episode_steps": 35,
        "num_rooms": 5,
        "num_objects": 8
    },
    "hard": {
        "difficulty": "hard",
        "max_episode_steps": 50,
        "num_rooms": 8,
        "num_objects": 12
    }
}
```

## æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•

### æ—¥å¿—ç³»ç»Ÿ
```python
# æ—¥å¿—çº§åˆ«é…ç½®
LOGGING_CONFIG = {
    "version": 1,
    "handlers": {
        "file": {
            "class": "logging.FileHandler",
            "filename": "logs/kgrl.log",
            "level": "INFO"
        },
        "console": {
            "class": "logging.StreamHandler",
            "level": "DEBUG"
        }
    },
    "loggers": {
        "Agent": {"level": "INFO"},
        "Environment": {"level": "INFO"},
        "KnowledgeGraph": {"level": "DEBUG"}
    }
}
```

### æ€§èƒ½æŒ‡æ ‡æ”¶é›†
```python
class MetricsCollector:
    def __init__(self):
        self.episode_rewards = []
        self.episode_lengths = []
        self.success_rate = 0.0
        self.invalid_action_rate = 0.0
        self.kg_retrieval_hits = 0
        self.api_call_times = []

    def log_episode(self, reward: float, length: int, success: bool):
        """è®°å½•å•ä¸ªepisodeçš„ç»“æœ"""

    def log_action(self, action: str, is_valid: bool, kg_used: bool):
        """è®°å½•å•ä¸ªåŠ¨ä½œçš„æ‰§è¡Œæƒ…å†µ"""

    def get_summary(self) -> Dict[str, float]:
        """è·å–æ€§èƒ½æ‘˜è¦ç»Ÿè®¡"""
```

è¿™ä¸ªæŠ€æœ¯æŠ¥å‘Šä¸ºåç»­çš„å®éªŒè®¾è®¡å’Œç³»ç»Ÿä¼˜åŒ–æä¾›äº†æ¸…æ™°çš„æ¶æ„æŒ‡å¯¼ã€‚
