#!/usr/bin/env python3
"""
æ ‡å‡†åŒ–Neo4jçŸ¥è¯†å›¾è°±å¯¼å…¥è„šæœ¬
ä¼˜åŒ–å¯¼å…¥æ€§èƒ½ï¼Œé¿å…å¡é¡¿é—®é¢˜

åŠŸèƒ½ï¼š
1. æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹å’Œè¾¹
2. ä¼˜åŒ–çš„æŸ¥è¯¢ç­–ç•¥
3. è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯å¤„ç†
4. æ”¯æŒå¤šç§KGæ ¼å¼
"""

import sys
import json
import time
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from neo4j import GraphDatabase
    NEO4J_AVAILABLE = True
except ImportError:
    NEO4J_AVAILABLE = False
    print("âŒ Neo4j driveræœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install neo4j")
    sys.exit(1)

from src.utils.logging_utils import setup_logging


class OptimizedNeo4jImporter:
    """ä¼˜åŒ–çš„Neo4jçŸ¥è¯†å›¾è°±å¯¼å…¥å™¨"""
    
    def __init__(self, uri: str = "bolt://localhost:7687", 
                 user: str = "neo4j", password: str = "yuanxi98"):
        """åˆå§‹åŒ–å¯¼å…¥å™¨"""
        self.uri = uri
        self.user = user
        self.password = password
        self.driver = None
        self.logger = logging.getLogger("Neo4jImporter")
        self.logger.setLevel(logging.INFO)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
        
        # æ‰¹é‡å¯¼å…¥é…ç½®
        self.batch_size = 1000  # æ¯æ‰¹å¤„ç†çš„èŠ‚ç‚¹/è¾¹æ•°é‡
        self.max_retries = 3    # æœ€å¤§é‡è¯•æ¬¡æ•°
        
    def connect(self) -> bool:
        """è¿æ¥åˆ°Neo4jæ•°æ®åº“"""
        try:
            self.driver = GraphDatabase.driver(self.uri, auth=(self.user, self.password))
            
            # æµ‹è¯•è¿æ¥
            with self.driver.session() as session:
                result = session.run("RETURN 1 as test")
                test_value = result.single()['test']
                
            self.logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°Neo4j: {self.uri}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è¿æ¥Neo4jå¤±è´¥: {e}")
            self.logger.error("   è¯·ç¡®ä¿Neo4jæœåŠ¡æ­£åœ¨è¿è¡Œ")
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.driver:
            self.driver.close()
            self.logger.info("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def clear_database(self) -> bool:
        """æ¸…ç©ºæ•°æ®åº“"""
        try:
            with self.driver.session() as session:
                # åˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»
                session.run("MATCH (n) DETACH DELETE n")
                
            self.logger.info("ğŸ§¹ æ•°æ®åº“å·²æ¸…ç©º")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def create_indexes(self) -> bool:
        """åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½"""
        try:
            with self.driver.session() as session:
                # ä¸ºå¸¸ç”¨å±æ€§åˆ›å»ºç´¢å¼•
                indexes = [
                    "CREATE INDEX entity_id_index IF NOT EXISTS FOR (n:Entity) ON (n.id)",
                    "CREATE INDEX entity_name_index IF NOT EXISTS FOR (n:Entity) ON (n.name)",
                    "CREATE INDEX action_id_index IF NOT EXISTS FOR (n:Action) ON (n.id)",
                    "CREATE INDEX state_id_index IF NOT EXISTS FOR (n:State) ON (n.id)",
                ]
                
                for index_query in indexes:
                    session.run(index_query)
                
            self.logger.info("ğŸ“Š ç´¢å¼•åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def import_kg_from_json(self, json_file: str, progress_callback=None) -> bool:
        """ä»JSONæ–‡ä»¶å¯¼å…¥çŸ¥è¯†å›¾è°± - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            self.logger.info(f"ğŸ“ åŠ è½½KGæ–‡ä»¶: {json_file}")
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            nodes = data.get('nodes', [])
            edges = data.get('edges', [])
            
            self.logger.info(f"ğŸ“Š KGç»Ÿè®¡: {len(nodes)} èŠ‚ç‚¹, {len(edges)} è¾¹")
            
            # æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹
            if not self._import_nodes_batch(nodes, progress_callback):
                return False
            
            # æ‰¹é‡å¯¼å…¥è¾¹
            if not self._import_edges_batch(edges, progress_callback):
                return False
            
            self.logger.info("âœ… KGå¯¼å…¥å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¼å…¥KGå¤±è´¥: {e}")
            return False
    
    def _import_nodes_batch(self, nodes: List[Dict], progress_callback=None) -> bool:
        """æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹"""
        try:
            total_nodes = len(nodes)
            self.logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¯¼å…¥ {total_nodes} ä¸ªèŠ‚ç‚¹...")
            
            with self.driver.session() as session:
                for i in range(0, total_nodes, self.batch_size):
                    batch = nodes[i:i + self.batch_size]
                    batch_num = i // self.batch_size + 1
                    total_batches = (total_nodes + self.batch_size - 1) // self.batch_size
                    
                    self.logger.info(f"   ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} èŠ‚ç‚¹)")
                    
                    # æ„å»ºæ‰¹é‡æ’å…¥æŸ¥è¯¢
                    query = self._build_batch_node_query()
                    
                    # å‡†å¤‡æ‰¹é‡æ•°æ®
                    batch_data = []
                    for node in batch:
                        node_data = {
                            'id': node['id'],
                            'name': node['name'],
                            'type': node['type'],
                            'label': self._get_node_label(node['type']),
                            'attributes': self._serialize_attributes(node.get('attributes', {}))
                        }
                        batch_data.append(node_data)
                    
                    # æ‰§è¡Œæ‰¹é‡æ’å…¥
                    session.run(query, nodes=batch_data)
                    
                    if progress_callback:
                        progress_callback(i + len(batch), total_nodes, "nodes")
            
            self.logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {total_nodes} ä¸ªèŠ‚ç‚¹")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def _import_edges_batch(self, edges: List[Dict], progress_callback=None) -> bool:
        """æ‰¹é‡å¯¼å…¥è¾¹ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            total_edges = len(edges)
            self.logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¯¼å…¥ {total_edges} æ¡è¾¹...")
            
            with self.driver.session() as session:
                for i in range(0, total_edges, self.batch_size):
                    batch = edges[i:i + self.batch_size]
                    batch_num = i // self.batch_size + 1
                    total_batches = (total_edges + self.batch_size - 1) // self.batch_size
                    
                    self.logger.info(f"   ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} æ¡è¾¹)")
                    
                    # ä½¿ç”¨ä¼˜åŒ–çš„è¾¹å¯¼å…¥ç­–ç•¥
                    success = self._import_edge_batch_optimized(session, batch)
                    
                    if not success:
                        self.logger.warning(f"   âš ï¸ æ‰¹æ¬¡ {batch_num} éƒ¨åˆ†å¤±è´¥ï¼Œç»§ç»­å¤„ç†...")
                    
                    if progress_callback:
                        progress_callback(i + len(batch), total_edges, "edges")
            
            self.logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {total_edges} æ¡è¾¹")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡å¯¼å…¥è¾¹å¤±è´¥: {e}")
            return False
    
    def _import_edge_batch_optimized(self, session, batch: List[Dict]) -> bool:
        """ä¼˜åŒ–çš„è¾¹æ‰¹é‡å¯¼å…¥"""
        try:
            # ä½¿ç”¨UNWINDè¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œé¿å…é€ä¸ªæŸ¥è¯¢
            query = """
            UNWIND $edges AS edge
            MATCH (a {id: edge.source})
            MATCH (b {id: edge.target})
            CALL apoc.create.relationship(a, edge.rel_type, edge.attributes, b) YIELD rel
            RETURN count(rel) as created
            """
            
            # å¦‚æœæ²¡æœ‰APOCæ’ä»¶ï¼Œä½¿ç”¨æ ‡å‡†æŸ¥è¯¢
            fallback_query = """
            UNWIND $edges AS edge
            MATCH (a {id: edge.source})
            MATCH (b {id: edge.target})
            CREATE (a)-[r:RELATES]->(b)
            SET r = edge.attributes
            SET r.type = edge.rel_type
            RETURN count(r) as created
            """
            
            # å‡†å¤‡æ‰¹é‡æ•°æ®
            batch_data = []
            for edge in batch:
                edge_data = {
                    'source': edge['source'],
                    'target': edge['target'],
                    'rel_type': self._get_relationship_type(edge['type']),
                    'attributes': self._serialize_attributes(edge.get('attributes', {}))
                }
                batch_data.append(edge_data)
            
            try:
                # å°è¯•ä½¿ç”¨APOCæŸ¥è¯¢
                result = session.run(query, edges=batch_data)
                created = result.single()['created']
            except:
                # å›é€€åˆ°æ ‡å‡†æŸ¥è¯¢
                result = session.run(fallback_query, edges=batch_data)
                created = result.single()['created']
            
            return created > 0
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡å¯¼å…¥è¾¹å‡ºé”™: {e}")
            return False
    
    def _build_batch_node_query(self) -> str:
        """æ„å»ºæ‰¹é‡èŠ‚ç‚¹æ’å…¥æŸ¥è¯¢ - ä¸ä½¿ç”¨APOC"""
        return """
        UNWIND $nodes AS node
        CALL {
            WITH node
            CREATE (n)
            SET n = node.attributes
            SET n.id = node.id, n.name = node.name, n.type = node.type
            WITH n, node.label as label
            CALL apoc.create.addLabels(n, [label]) YIELD node as labeled_node
            RETURN labeled_node
        }
        RETURN count(*) as created
        """
    
    def _get_node_label(self, node_type: str) -> str:
        """è·å–èŠ‚ç‚¹æ ‡ç­¾"""
        label_mapping = {
            'action': 'Action',
            'entity': 'Entity', 
            'state': 'State',
            'result': 'Result',
            'condition': 'Condition',
            'rule': 'Rule'
        }
        return label_mapping.get(node_type, node_type.capitalize())
    
    def _get_relationship_type(self, edge_type: str) -> str:
        """è·å–å…³ç³»ç±»å‹"""
        rel_mapping = {
            'requires': 'REQUIRES',
            'produces': 'PRODUCES',
            'modifies': 'MODIFIES',
            'enables': 'ENABLES',
            'prevents': 'PREVENTS',
            'has_state': 'HAS_STATE',
            'located_in': 'LOCATED_IN',
            'connected_to': 'CONNECTED_TO'
        }
        return rel_mapping.get(edge_type, edge_type.upper())
    
    def _serialize_attributes(self, attributes: Dict[str, Any]) -> Dict[str, Any]:
        """åºåˆ—åŒ–å±æ€§"""
        serialized = {}
        for key, value in attributes.items():
            if isinstance(value, (str, int, float, bool)):
                serialized[key] = value
            elif isinstance(value, (list, dict)):
                serialized[key] = json.dumps(value, ensure_ascii=False)
            else:
                serialized[key] = str(value)
        return serialized
    
    def get_statistics(self) -> Dict[str, int]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self.driver.session() as session:
                # ç»Ÿè®¡èŠ‚ç‚¹
                node_result = session.run("MATCH (n) RETURN count(n) as node_count")
                node_count = node_result.single()['node_count']
                
                # ç»Ÿè®¡å…³ç³»
                rel_result = session.run("MATCH ()-[r]->() RETURN count(r) as rel_count")
                rel_count = rel_result.single()['rel_count']
                
                # ç»Ÿè®¡æ ‡ç­¾
                label_result = session.run("CALL db.labels() YIELD label RETURN count(label) as label_count")
                label_count = label_result.single()['label_count']
                
                return {
                    'nodes': node_count,
                    'relationships': rel_count,
                    'labels': label_count
                }
                
        except Exception as e:
            self.logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


def progress_callback(current: int, total: int, item_type: str):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    percentage = (current / total) * 100
    print(f"   ğŸ“ˆ {item_type}: {current}/{total} ({percentage:.1f}%)")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ ‡å‡†åŒ–Neo4jçŸ¥è¯†å›¾è°±å¯¼å…¥è„šæœ¬")
    parser.add_argument("--file", type=str, help="è¦å¯¼å…¥çš„KG JSONæ–‡ä»¶")
    parser.add_argument("--scene", type=str, help="å¯¼å…¥ç‰¹å®šåœºæ™¯")
    parser.add_argument("--all-scenes", action="store_true", help="å¯¼å…¥æ‰€æœ‰å¢å¼ºåœºæ™¯")
    parser.add_argument("--uri", type=str, default="bolt://localhost:7687", help="Neo4j URI")
    parser.add_argument("--user", type=str, default="neo4j", help="Neo4jç”¨æˆ·å")
    parser.add_argument("--password", type=str, default="yuanxi98", help="Neo4jå¯†ç ")
    parser.add_argument("--clear", action="store_true", help="å¯¼å…¥å‰æ¸…ç©ºæ•°æ®åº“")
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯¼å…¥å™¨
    importer = OptimizedNeo4jImporter(args.uri, args.user, args.password)
    
    print("ğŸš€ æ ‡å‡†åŒ–Neo4jçŸ¥è¯†å›¾è°±å¯¼å…¥å™¨")
    print(f"ğŸŒ Neo4j URI: {args.uri}")
    
    # è¿æ¥æ•°æ®åº“
    if not importer.connect():
        return
    
    try:
        # æ¸…ç©ºæ•°æ®åº“
        if args.clear:
            print("ğŸ§¹ æ¸…ç©ºæ•°æ®åº“...")
            importer.clear_database()
        
        # åˆ›å»ºç´¢å¼•
        print("ğŸ“Š åˆ›å»ºç´¢å¼•...")
        importer.create_indexes()
        
        # ç¡®å®šè¦å¯¼å…¥çš„æ–‡ä»¶
        kg_files = []
        
        if args.file:
            kg_files.append(Path(args.file))
        elif args.scene:
            kg_file = project_root / f"data/kg/enhanced_scenes/{args.scene}_enhanced_kg.json"
            if kg_file.exists():
                kg_files.append(kg_file)
            else:
                print(f"âŒ åœºæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {kg_file}")
                return
        elif args.all_scenes:
            scenes_dir = project_root / "data/kg/enhanced_scenes"
            kg_files = list(scenes_dir.glob("*_enhanced_kg.json"))
        else:
            # é»˜è®¤å¯¼å…¥å®éªŒåœºæ™¯
            scenes = ['FloorPlan202-openable', 'FloorPlan308-openable']
            for scene in scenes:
                kg_file = project_root / f"data/kg/enhanced_scenes/{scene}_enhanced_kg.json"
                if kg_file.exists():
                    kg_files.append(kg_file)
        
        if not kg_files:
            print("âŒ æœªæ‰¾åˆ°è¦å¯¼å…¥çš„KGæ–‡ä»¶")
            return
        
        # å¯¼å…¥æ–‡ä»¶
        success_count = 0
        for kg_file in kg_files:
            print(f"\nğŸ—ï¸ å¯¼å…¥æ–‡ä»¶: {kg_file.name}")
            
            start_time = time.time()
            if importer.import_kg_from_json(str(kg_file), progress_callback):
                elapsed = time.time() - start_time
                print(f"âœ… å¯¼å…¥æˆåŠŸ (è€—æ—¶: {elapsed:.1f}ç§’)")
                success_count += 1
            else:
                print(f"âŒ å¯¼å…¥å¤±è´¥")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆç»Ÿè®¡:")
        print(f"   - æˆåŠŸå¯¼å…¥: {success_count}/{len(kg_files)} ä¸ªæ–‡ä»¶")
        
        final_stats = importer.get_statistics()
        for key, value in final_stats.items():
            print(f"   - {key}: {value}")
        
        print(f"\nğŸ‰ çŸ¥è¯†å›¾è°±å¯¼å…¥å®Œæˆ!")
        print(f"ğŸŒ è¯·åœ¨Neo4j Browserä¸­æŸ¥çœ‹: http://localhost:7474")
        
    finally:
        importer.close()


if __name__ == "__main__":
    main()
