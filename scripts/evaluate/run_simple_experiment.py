#!/usr/bin/env python3
"""
ç®€åŒ–çš„KGRLå®éªŒè„šæœ¬
ä½¿ç”¨ç®€åŒ–é…ç½®ï¼Œæ¸…æ™°çš„é€»è¾‘ï¼Œè¯¦ç»†çš„è¾“å‡º
"""

import os
import sys
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.utils.simple_config import get_config
from src.agents.baseline_agents import LLMBaselineAgent, ReActAgent, RAGAgent
from src.environments.scene_based_env import SceneBasedEnvironment
from src.utils.agent_path_tracker import AgentPathTracker

def setup_experiment() -> Tuple[str, Dict[str, Any]]:
    """è®¾ç½®å®éªŒ"""
    print("ğŸ”§ è®¾ç½®å®éªŒç¯å¢ƒ...")
    
    # åŠ è½½é…ç½®
    config = get_config()
    
    # éªŒè¯é…ç½®
    if not config.validate():
        raise ValueError("é…ç½®éªŒè¯å¤±è´¥")
    
    # æ‰“å°é…ç½®æ‘˜è¦
    config.print_summary()
    
    # åˆ›å»ºå®éªŒç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_id = f"simple_experiment_{timestamp}"
    
    experiment_dir = project_root / "experiments" / "results" / experiment_id
    experiment_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•
    (experiment_dir / "logs").mkdir(exist_ok=True)
    (experiment_dir / "results").mkdir(exist_ok=True)
    
    print(f"ğŸ“ å®éªŒç›®å½•: {experiment_dir}")
    
    # ä¿å­˜é…ç½®åˆ°å®éªŒç›®å½•
    config.save(experiment_dir / "config.yaml")
    
    return str(experiment_dir), config.config

def run_agent_episode(agent, agent_name: str, env, scene_name: str,
                     config: Dict[str, Any], experiment_dir: str) -> Dict[str, Any]:
    """è¿è¡Œå•ä¸ªæ™ºèƒ½ä½“çš„episode"""
    agent_emoji = {'llm_baseline': 'ğŸ¤–', 'react': 'ğŸ§ ', 'rag': 'ğŸ”'}
    agent_desc = {
        'llm_baseline': 'LLMåŸºçº¿æ™ºèƒ½ä½“ (çº¯LLMæ¨ç†)',
        'react': 'ReActæ™ºèƒ½ä½“ (æ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿ)',
        'rag': 'RAGæ™ºèƒ½ä½“ (æ£€ç´¢å¢å¼ºç”Ÿæˆ)'
    }

    print(f"\n{'ğŸš€' * 25}")
    print(f"{agent_emoji.get(agent_name, 'ğŸ¤–')} ã€{agent_name.upper()}ã€‘ {agent_desc.get(agent_name, agent_name)}")
    print(f"ğŸ  åœºæ™¯: {scene_name}")
    print(f"{'ğŸš€' * 25}")
    print()
    
    # é‡ç½®ç¯å¢ƒå’Œæ™ºèƒ½ä½“åˆ°æŒ‡å®šåœºæ™¯
    observation = env.reset(scene_name)
    agent.reset({'scene_name': scene_name})
    
    # åˆ›å»ºè·¯å¾„è¿½è¸ªå™¨
    tracker = AgentPathTracker(scene_name)
    
    # å®éªŒé…ç½®
    max_steps = config.get('experiment', {}).get('max_steps_per_episode', 10)
    
    # è®°å½•episodeä¿¡æ¯
    episode_data = {
        'agent': agent_name,
        'scene': scene_name,
        'start_time': datetime.now().isoformat(),
        'steps': [],
        'total_reward': 0.0,
        'success': False
    }
    
    print(f"ğŸŒ åˆå§‹è§‚å¯Ÿ:")
    print(f"  ä½ç½®: {observation.get('agent_location', 'unknown')}")
    print(f"  å¯è§å®ä½“: {observation.get('visible_entities', [])[:5]}...")
    print(f"  åº“å­˜: {observation.get('agent_inventory', [])}")
    print(f"  å¯ç”¨åŠ¨ä½œ: {observation.get('available_actions', [])}")
    
    for step in range(1, max_steps + 1):
        print(f"\nğŸ”„ æ­¥éª¤ {step}/{max_steps}")
        print(f"{'â”€'*40}")
        
        step_start_time = time.time()
        
        # æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
        if agent_name == 'rag' and hasattr(agent, 'select_action_with_tracking'):
            # RAGæ™ºèƒ½ä½“ä½¿ç”¨è¿½è¸ªç‰ˆæœ¬
            action, target, kg_nodes_accessed, reasoning_trace = agent.select_action_with_tracking(observation)
            
            # è®°å½•KGèŠ‚ç‚¹è®¿é—®
            tracker.record_step(
                agent_name=agent_name,
                step=step,
                action=action,
                target=target,
                reward=0.0,  # å°†åœ¨æ‰§è¡Œåæ›´æ–°
                kg_nodes_accessed=kg_nodes_accessed,
                reasoning_trace=reasoning_trace,
                observation=observation
            )
            
            print(f"ğŸ”— è®¿é—®äº† {len(kg_nodes_accessed)} ä¸ªKGèŠ‚ç‚¹")
            
        else:
            # å…¶ä»–æ™ºèƒ½ä½“ä½¿ç”¨æ ‡å‡†ç‰ˆæœ¬
            action, target = agent.select_action(observation)
            
            # è®°å½•æ­¥éª¤ï¼ˆæ— KGèŠ‚ç‚¹è®¿é—®ï¼‰
            tracker.record_step(
                agent_name=agent_name,
                step=step,
                action=action,
                target=target,
                reward=0.0,  # å°†åœ¨æ‰§è¡Œåæ›´æ–°
                kg_nodes_accessed=[],
                reasoning_trace=f"{agent_name}: {action} -> {target}",
                observation=observation
            )
        
        step_time = time.time() - step_start_time
        
        # æ‰§è¡ŒåŠ¨ä½œ
        print(f"ğŸ¬ æ‰§è¡ŒåŠ¨ä½œ: {action} -> {target}")
        try:
            observation, reward, done, info = env.step(action, target)
            print(f"ğŸ† å¥–åŠ±: {reward}")
            print(f"âœ… å®Œæˆ: {done}")
            if info:
                print(f"â„¹ï¸ ä¿¡æ¯: {info}")
            
            # æ›´æ–°è¿½è¸ªå™¨ä¸­çš„å¥–åŠ±
            if tracker.paths:
                tracker.paths[-1]['reward'] = reward
            
        except Exception as e:
            print(f"âŒ åŠ¨ä½œæ‰§è¡Œå¤±è´¥: {e}")
            reward = -0.1
            done = False
            info = {'error': str(e)}
        
        # è®°å½•æ­¥éª¤è¯¦æƒ…
        step_info = {
            'step': step,
            'action': action,
            'target': target,
            'reward': reward,
            'step_time': step_time,
            'done': done,
            'info': info
        }
        
        if agent_name == 'rag':
            step_info['kg_nodes_accessed'] = kg_nodes_accessed if 'kg_nodes_accessed' in locals() else []
            step_info['reasoning_trace'] = reasoning_trace if 'reasoning_trace' in locals() else ""
        
        episode_data['steps'].append(step_info)
        episode_data['total_reward'] += reward
        
        print(f"ğŸ“Š æ­¥éª¤æ€»ç»“:")
        print(f"  - åŠ¨ä½œ: {action} -> {target}")
        print(f"  - å¥–åŠ±: {reward}")
        print(f"  - ç´¯è®¡å¥–åŠ±: {episode_data['total_reward']:.3f}")
        print(f"  - ç”¨æ—¶: {step_time:.3f}s")
        
        if done:
            print(f"ğŸ‰ EpisodeæˆåŠŸå®Œæˆ!")
            episode_data['success'] = True
            break
    
    episode_data['end_time'] = datetime.now().isoformat()
    episode_data['total_steps'] = len(episode_data['steps'])
    
    # ä¿å­˜è¯¦ç»†æ—¥å¿—
    log_file = Path(experiment_dir) / "logs" / f"{agent_name}_{scene_name}.json"
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(episode_data, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜è·¯å¾„è¿½è¸ª
    tracker.save_results(str(Path(experiment_dir) / "results"))
    
    print(f"\nğŸ“ˆ {agent_name} Episodeæ€»ç»“:")
    print(f"  - æ€»æ­¥æ•°: {episode_data['total_steps']}")
    print(f"  - æ€»å¥–åŠ±: {episode_data['total_reward']:.3f}")
    print(f"  - æˆåŠŸ: {episode_data['success']}")

    # æ·»åŠ æ™ºèƒ½ä½“å®Œæˆæ ‡è¯†
    print(f"\n{'ğŸ”š' * 20} {agent_name.upper()} å®Œæˆ {'ğŸ”š' * 20}")
    print(f"â±ï¸  ç­‰å¾…ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“...")
    time.sleep(1)  # çŸ­æš‚æš‚åœä»¥ä¾¿è§‚å¯Ÿ

    return episode_data

def main():
    """ä¸»å®éªŒå‡½æ•°"""
    print("ğŸ§ª KGRL ç®€åŒ–å®éªŒ")
    print("=" * 60)
    
    try:
        # è®¾ç½®å®éªŒ
        experiment_dir, config = setup_experiment()
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        print(f"\nğŸŒ åˆå§‹åŒ–ç¯å¢ƒ...")
        env = SceneBasedEnvironment()
        
        # è·å–å®éªŒé…ç½®
        experiment_config = config.get('experiment', {})
        scenes = experiment_config.get('scenes', ['FloorPlan202-openable'])
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“ - ä¼ å…¥é…ç½®
        llm_config = config.get('llm', {})
        agents_config = config.get('agents', {})

        agents = {
            'llm_baseline': LLMBaselineAgent(llm_config),
            'react': ReActAgent(llm_config),
            'rag': RAGAgent({**llm_config, **agents_config.get('rag', {})})
        }
        
        # è¿è¡Œå®éªŒ
        all_results = {}
        
        for scene_name in scenes:
            print(f"\nğŸ  åŠ è½½åœºæ™¯: {scene_name}")
            
            try:
                # é‡ç½®ç¯å¢ƒåˆ°æŒ‡å®šåœºæ™¯
                env.reset(scene_name)
                scene_results = {}
                
                # è¿è¡Œæ¯ä¸ªæ™ºèƒ½ä½“
                for agent_name, agent in agents.items():
                    try:
                        episode_result = run_agent_episode(
                            agent=agent,
                            agent_name=agent_name,
                            env=env,
                            scene_name=scene_name,
                            config=config,
                            experiment_dir=experiment_dir
                        )
                        scene_results[agent_name] = episode_result
                        
                    except Exception as e:
                        print(f"âŒ è¿è¡Œ {agent_name} æ—¶å‡ºé”™: {e}")
                        scene_results[agent_name] = {
                            'error': str(e),
                            'total_reward': 0.0,
                            'total_steps': 0,
                            'success': False
                        }
                
                all_results[scene_name] = scene_results
                
            except Exception as e:
                print(f"âŒ åŠ è½½åœºæ™¯ {scene_name} æ—¶å‡ºé”™: {e}")
                all_results[scene_name] = {'error': str(e)}
        
        # ä¿å­˜æ€»ç»“æœ
        results_file = Path(experiment_dir) / "results" / "experiment_results.json"
        with open(results_file, 'w') as f:
            json.dump(all_results, f, indent=2)
        
        print(f"\nğŸ‰ å®éªŒå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {experiment_dir}")
        print(f"ğŸ“Š è¯¦ç»†æ—¥å¿—åœ¨: {experiment_dir}/logs/")
        
    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
