#!/usr/bin/env python3
"""
ç»¼åˆå®éªŒè¿è¡Œå™¨ - çœŸå®æ•°æ®æµ‹è¯•ï¼ŒåŒ…å«å®Œæ•´çš„KGèŠ‚ç‚¹è¿½è¸ª
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))
sys.path.append(str(project_root / "tools" / "visualization"))

from src.environments.scene_based_env import SceneBasedEnvironment
from src.agents.baseline_agents import LLMBaselineAgent, ReActAgent, RAGAgent
from agent_path_tracker import AgentPathTracker

class ComprehensiveExperimentRunner:
    """ç»¼åˆå®éªŒè¿è¡Œå™¨"""
    
    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_id = f"comprehensive_experiment_{self.timestamp}"
        
        # åˆ›å»ºå®éªŒç›®å½•
        self.experiment_dir = project_root / "experiments" / "results" / self.experiment_id
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # å­ç›®å½•
        self.results_dir = self.experiment_dir / "results"
        self.reports_dir = self.experiment_dir / "reports"
        self.visualizations_dir = self.experiment_dir / "visualizations"
        
        for dir_path in [self.results_dir, self.reports_dir, self.visualizations_dir]:
            dir_path.mkdir(exist_ok=True)
        
        print(f"ğŸ§ª Comprehensive Experiment: {self.experiment_id}")
        print(f"ğŸ“ Experiment Directory: {self.experiment_dir}")
    
    def run_experiment(self, scenes: List[str] = None, max_episodes: int = 3, max_steps: int = 10):
        """è¿è¡Œç»¼åˆå®éªŒ"""
        print("=" * 80)
        print("ğŸš€ Starting Comprehensive KGRL Experiment")
        print("=" * 80)
        
        # é»˜è®¤åœºæ™¯
        if scenes is None:
            scenes = ["FloorPlan202-openable", "FloorPlan308-openable"]
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        print("ğŸŒ Initializing Environment...")
        env = SceneBasedEnvironment()
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        print("ğŸ¤– Initializing Agents...")
        agents = {
            "llm_baseline": LLMBaselineAgent(model_name="gpt-3.5-turbo"),
            "react": ReActAgent(),
            "rag": RAGAgent()
        }
        
        # å®éªŒç»“æœå­˜å‚¨
        experiment_results = {
            'experiment_id': self.experiment_id,
            'timestamp': self.timestamp,
            'config': {
                'scenes': scenes,
                'max_episodes': max_episodes,
                'max_steps': max_steps,
                'agents': list(agents.keys())
            },
            'results': {},
            'summary': {}
        }
        
        # å¯¹æ¯ä¸ªåœºæ™¯è¿è¡Œå®éªŒ
        for scene_name in scenes:
            print(f"\nğŸ¯ Testing Scene: {scene_name}")
            scene_results = self._run_scene_experiment(
                env, agents, scene_name, max_episodes, max_steps
            )
            experiment_results['results'][scene_name] = scene_results
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\nğŸ“Š Generating Comprehensive Report...")
        self._generate_comprehensive_report(experiment_results)
        
        # ä¿å­˜å®éªŒç»“æœ
        results_file = self.results_dir / "experiment_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(experiment_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… Experiment Complete!")
        print(f"ğŸ“ Results saved to: {self.experiment_dir}")
        
        return experiment_results
    
    def _run_scene_experiment(self, env, agents, scene_name: str, 
                            max_episodes: int, max_steps: int) -> Dict:
        """è¿è¡Œå•ä¸ªåœºæ™¯çš„å®éªŒ"""
        print(f"  ğŸ“‹ Scene: {scene_name}")
        
        # åˆ›å»ºè·¯å¾„è¿½è¸ªå™¨
        tracker = AgentPathTracker(scene_name)
        
        # åœºæ™¯ç»“æœ
        scene_results = {
            'scene_name': scene_name,
            'agents': {},
            'episodes': max_episodes,
            'max_steps': max_steps
        }
        
        # è¿è¡Œå¤šä¸ªå›åˆ
        for episode in range(max_episodes):
            print(f"    ğŸ“‹ Episode {episode + 1}/{max_episodes}")
            tracker.start_episode(episode + 1)
            
            # æµ‹è¯•æ¯ä¸ªæ™ºèƒ½ä½“
            for agent_name, agent in agents.items():
                print(f"      ğŸ¤– Agent: {agent_name}")
                
                if agent_name not in scene_results['agents']:
                    scene_results['agents'][agent_name] = {
                        'episodes': [],
                        'total_reward': 0,
                        'total_steps': 0,
                        'kg_nodes_accessed': set()
                    }
                
                # è¿è¡Œå•ä¸ªæ™ºèƒ½ä½“çš„å›åˆ
                episode_result = self._run_agent_episode(
                    env, agent, agent_name, scene_name, max_steps, tracker
                )
                
                scene_results['agents'][agent_name]['episodes'].append(episode_result)
                scene_results['agents'][agent_name]['total_reward'] += episode_result['total_reward']
                scene_results['agents'][agent_name]['total_steps'] += episode_result['steps']
                scene_results['agents'][agent_name]['kg_nodes_accessed'].update(
                    episode_result.get('kg_nodes_accessed', [])
                )
        
        # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        for agent_data in scene_results['agents'].values():
            agent_data['kg_nodes_accessed'] = list(agent_data['kg_nodes_accessed'])
        
        # ä¿å­˜è·¯å¾„æ•°æ®
        json_file, csv_file = tracker.save_paths(self.results_dir)
        md_file = tracker.generate_path_table(self.reports_dir)
        
        scene_results['files'] = {
            'path_json': str(json_file),
            'path_csv': str(csv_file),
            'path_report': str(md_file)
        }
        
        return scene_results
    
    def _run_agent_episode(self, env, agent, agent_name: str, scene_name: str, 
                          max_steps: int, tracker: AgentPathTracker) -> Dict:
        """è¿è¡Œå•ä¸ªæ™ºèƒ½ä½“çš„å•ä¸ªå›åˆ"""
        
        # é‡ç½®ç¯å¢ƒ
        observation = env.reset(scene_name)
        
        episode_result = {
            'agent': agent_name,
            'scene': scene_name,
            'steps': 0,
            'total_reward': 0,
            'actions': [],
            'kg_nodes_accessed': [],
            'reasoning_traces': []
        }
        
        print(f"        ğŸ‘ï¸ Initial observation: {observation.get('visible_entities', [])[:3]}...")
        
        # è¿è¡Œæ­¥éª¤
        for step in range(max_steps):
            try:
                # è®°å½•æ­¥éª¤å¼€å§‹
                step_start_time = time.time()
                
                # æ™ºèƒ½ä½“å†³ç­–ï¼ˆåŒ…å«KGèŠ‚ç‚¹è®¿é—®è¿½è¸ªï¼‰
                if agent_name == "rag":
                    # RAGæ™ºèƒ½ä½“éœ€è¦ç‰¹æ®Šå¤„ç†ä»¥è¿½è¸ªKGè®¿é—®
                    action_name, target, kg_nodes, reasoning = self._get_rag_action_with_tracking(
                        agent, observation
                    )
                else:
                    # å…¶ä»–æ™ºèƒ½ä½“
                    action_name, target = agent.select_action(observation)
                    kg_nodes = []
                    reasoning = f"{agent_name} selected {action_name} -> {target}"
                
                action = {"action": action_name, "target": target}
                
                # æ‰§è¡ŒåŠ¨ä½œ
                observation, reward, done, info = env.step(action)
                
                # è®°å½•æ­¥éª¤
                step_time = time.time() - step_start_time
                
                episode_result['steps'] += 1
                episode_result['total_reward'] += reward
                episode_result['actions'].append({
                    'step': step + 1,
                    'action': action_name,
                    'target': target,
                    'reward': reward,
                    'step_time': step_time
                })
                episode_result['kg_nodes_accessed'].extend(kg_nodes)
                episode_result['reasoning_traces'].append(reasoning)
                
                # è®°å½•åˆ°è¿½è¸ªå™¨
                tracker.record_step(
                    agent_name=agent_name,
                    action=action_name,
                    target=target if target else 'none',
                    observation=observation,
                    reward=reward,
                    kg_nodes_accessed=kg_nodes,
                    reasoning_trace=reasoning
                )
                
                print(f"          Step {step + 1}: {action_name} -> {target} "
                      f"(KG nodes: {len(kg_nodes)}, Reward: {reward:.3f})")
                
                if done:
                    print(f"          âœ… Task completed!")
                    break
                    
            except Exception as e:
                print(f"          âŒ Error in step {step + 1}: {e}")
                # è®°å½•é”™è¯¯æ­¥éª¤
                tracker.record_step(
                    agent_name=agent_name,
                    action="error",
                    target="none",
                    observation=observation,
                    reward=-0.1,
                    kg_nodes_accessed=[],
                    reasoning_trace=f"Error: {str(e)}"
                )
                break
        
        print(f"        ğŸ“Š Episode complete: {episode_result['steps']} steps, "
              f"reward: {episode_result['total_reward']:.3f}, "
              f"KG nodes: {len(set(episode_result['kg_nodes_accessed']))}")
        
        return episode_result
    
    def _get_rag_action_with_tracking(self, agent, observation) -> Tuple[str, str, List[str], str]:
        """è·å–RAGæ™ºèƒ½ä½“çš„åŠ¨ä½œï¼ŒåŒæ—¶è¿½è¸ªKGèŠ‚ç‚¹è®¿é—®"""
        # ä½¿ç”¨RAGæ™ºèƒ½ä½“çš„è¿½è¸ªæ–¹æ³•
        if hasattr(agent, 'select_action_with_tracking'):
            return agent.select_action_with_tracking(observation)
        else:
            # å›é€€åˆ°æ™®é€šæ–¹æ³•
            action_name, target = agent.select_action(observation)
            visible_entities = observation.get('visible_entities', [])
            kg_nodes_accessed = [entity for entity in visible_entities if entity != target]
            reasoning = f"RAG: Retrieved {len(kg_nodes_accessed)} nodes, selected {action_name} -> {target}"
            return action_name, target, kg_nodes_accessed, reasoning
    
    def _generate_comprehensive_report(self, experiment_results: Dict):
        """ç”Ÿæˆç»¼åˆå®éªŒæŠ¥å‘Š"""
        report_file = self.reports_dir / "comprehensive_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Comprehensive KGRL Experiment Report\n\n")
            f.write(f"**Experiment ID**: {experiment_results['experiment_id']}\n")
            f.write(f"**Timestamp**: {experiment_results['timestamp']}\n\n")
            
            # é…ç½®ä¿¡æ¯
            config = experiment_results['config']
            f.write("## Experiment Configuration\n\n")
            f.write(f"- **Scenes**: {', '.join(config['scenes'])}\n")
            f.write(f"- **Episodes**: {config['max_episodes']}\n")
            f.write(f"- **Max Steps**: {config['max_steps']}\n")
            f.write(f"- **Agents**: {', '.join(config['agents'])}\n\n")
            
            # ç»“æœæ±‡æ€»
            f.write("## Results Summary\n\n")
            f.write("| Scene | Agent | Total Reward | Total Steps | Avg Reward | KG Nodes |\n")
            f.write("|-------|-------|--------------|-------------|------------|----------|\n")
            
            for scene_name, scene_data in experiment_results['results'].items():
                for agent_name, agent_data in scene_data['agents'].items():
                    avg_reward = agent_data['total_reward'] / agent_data['total_steps'] if agent_data['total_steps'] > 0 else 0
                    kg_nodes_count = len(agent_data['kg_nodes_accessed'])
                    
                    f.write(f"| {scene_name} | {agent_name} | {agent_data['total_reward']:.3f} | "
                           f"{agent_data['total_steps']} | {avg_reward:.3f} | {kg_nodes_count} |\n")
            
            f.write("\n## Detailed Analysis\n\n")
            f.write("See individual scene reports in the reports directory.\n")
        
        print(f"  âœ… Comprehensive report: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    runner = ComprehensiveExperimentRunner()
    
    # è¿è¡Œå®éªŒ
    results = runner.run_experiment(
        scenes=["FloorPlan202-openable", "FloorPlan308-openable"],
        max_episodes=2,
        max_steps=8
    )
    
    return results

if __name__ == "__main__":
    try:
        results = main()
        print(f"\nğŸ‰ Experiment completed successfully!")
        sys.exit(0)
    except KeyboardInterrupt:
        print("\nâš ï¸ Experiment interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Experiment failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
