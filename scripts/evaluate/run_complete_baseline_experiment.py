#!/usr/bin/env python3
"""
å®Œæ•´çš„åŸºçº¿å¯¹æ¯”å®éªŒ
åŒ…å«çœŸæ­£çš„LLMè°ƒç”¨ã€ReActã€RAGä¸‰æ¡çº¿
"""

import json
import time
import random
from pathlib import Path
from typing import Dict, Any, List
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.environments.scene_based_env import SceneBasedEnvironment
from src.utils.llm_client import LLMBaselineAgent
from src.agents.baseline_agents import ReActAgent, RAGAgent
from experiments.utils.visualization import ExperimentVisualizer


class CompleteBaselineExperiment:
    """å®Œæ•´çš„åŸºçº¿å¯¹æ¯”å®éªŒ"""
    
    def __init__(self, api_key: str, num_episodes: int = 20, max_steps: int = 15):
        self.api_key = api_key
        self.num_episodes = num_episodes
        self.max_steps = max_steps
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        self.env = SceneBasedEnvironment()
        
        # åˆå§‹åŒ–ä¸‰ä¸ªæ™ºèƒ½ä½“
        self.agents = {
            'llm_baseline': LLMBaselineAgent(api_key),
            'react': ReActAgent(),
            'rag': RAGAgent()
        }
        
        # ç»“æœè®°å½•
        self.results = {agent_name: {
            'rewards': [],
            'success_rates': [],
            'steps': [],
            'episode_details': []
        } for agent_name in self.agents.keys()}
        
        # å®éªŒé…ç½®
        self.experiment_config = {
            'num_episodes': num_episodes,
            'max_steps': max_steps,
            'agents': list(self.agents.keys()),
            'timestamp': int(time.time()),
            'api_key_provided': bool(api_key)
        }
        
        print(f"ğŸ§ª åˆå§‹åŒ–å®Œæ•´åŸºçº¿å®éªŒ (episodes: {num_episodes}, max_steps: {max_steps})")
    
    def run_single_episode(self, agent_name: str, agent, scene_name: str = None) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªepisode"""
        print(f"  ğŸ® è¿è¡Œ {agent_name} åœ¨åœºæ™¯ {scene_name}")
        
        # é‡ç½®ç¯å¢ƒ
        obs = self.env.reset(scene_name)
        agent.reset(obs)
        
        total_reward = 0
        steps = 0
        done = False
        episode_log = []
        
        while not done and steps < self.max_steps:
            # æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
            try:
                action, target = agent.select_action(obs)
                print(f"    æ­¥éª¤ {steps+1}: {action} {target or ''}")
            except Exception as e:
                print(f"    âŒ æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œå¤±è´¥: {e}")
                action, target = "wait", None
            
            # æ‰§è¡ŒåŠ¨ä½œ
            try:
                next_obs, reward, done, info = self.env.step(action, target)
            except Exception as e:
                print(f"    âŒ ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œå¤±è´¥: {e}")
                reward = -0.1
                done = True
                next_obs = obs
                info = {}
            
            # è®°å½•æ­¥éª¤
            step_log = {
                'step': steps,
                'action': action,
                'target': target,
                'reward': reward,
                'done': done
            }
            episode_log.append(step_log)
            
            # æ™ºèƒ½ä½“å­¦ä¹ /æ›´æ–°
            try:
                agent.update(obs, action, target, reward, next_obs, done)
            except Exception as e:
                print(f"    âš ï¸  æ™ºèƒ½ä½“æ›´æ–°å¤±è´¥: {e}")
            
            # æ›´æ–°çŠ¶æ€
            obs = next_obs
            total_reward += reward
            steps += 1
            
            # æ—©åœæ¡ä»¶
            if reward > 5:  # ä»»åŠ¡æˆåŠŸ
                done = True
                break
        
        # åˆ¤æ–­æˆåŠŸ
        success = info.get('task_completed', False) or total_reward > 3
        
        result = {
            'agent': agent_name,
            'scene': scene_name,
            'total_reward': total_reward,
            'steps': steps,
            'success': success,
            'episode_log': episode_log,
            'final_info': info
        }
        
        print(f"    ç»“æœ: å¥–åŠ±={total_reward:.2f}, æ­¥æ•°={steps}, æˆåŠŸ={success}")
        return result
    
    def run_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print(f"ğŸš€ å¼€å§‹å®Œæ•´åŸºçº¿å¯¹æ¯”å®éªŒ")
        
        # è·å–å¯ç”¨åœºæ™¯
        scenes = self.env.get_scene_list()
        if not scenes:
            print("âŒ æ²¡æœ‰å¯ç”¨åœºæ™¯ï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†å›¾è°±")
            return
        
        print(f"ğŸ“Š å¯ç”¨åœºæ™¯: {len(scenes)} ä¸ª")
        
        # é™åˆ¶åœºæ™¯æ•°é‡ä»¥åŠ å¿«å®éªŒ
        if len(scenes) > 5:
            scenes = random.sample(scenes, 5)
            print(f"ğŸ¯ éšæœºé€‰æ‹© {len(scenes)} ä¸ªåœºæ™¯è¿›è¡Œå®éªŒ")
        
        start_time = time.time()
        
        for episode in range(self.num_episodes):
            # éšæœºé€‰æ‹©åœºæ™¯
            scene_name = random.choice(scenes)
            
            print(f"\nğŸ® Episode {episode + 1}/{self.num_episodes} - åœºæ™¯: {scene_name}")
            
            # ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è¿è¡Œepisode
            for agent_name, agent in self.agents.items():
                try:
                    result = self.run_single_episode(agent_name, agent, scene_name)
                    
                    # è®°å½•ç»“æœ
                    self.results[agent_name]['rewards'].append(result['total_reward'])
                    self.results[agent_name]['success_rates'].append(1 if result['success'] else 0)
                    self.results[agent_name]['steps'].append(result['steps'])
                    self.results[agent_name]['episode_details'].append(result)
                    
                except Exception as e:
                    print(f"  âŒ {agent_name} æ‰§è¡Œå¤±è´¥: {e}")
                    # è®°å½•å¤±è´¥ç»“æœ
                    self.results[agent_name]['rewards'].append(-5)
                    self.results[agent_name]['success_rates'].append(0)
                    self.results[agent_name]['steps'].append(self.max_steps)
            
            # å®šæœŸæŠ¥å‘Šè¿›åº¦
            if (episode + 1) % 5 == 0:
                self._report_progress(episode + 1)
        
        # æœ€ç»ˆåˆ†æ
        self._final_analysis()
        
        # ä¿å­˜ç»“æœ
        results_file = self._save_results()
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations(results_file)
        
        total_time = time.time() - start_time
        print(f"â±ï¸  æ€»å®éªŒæ—¶é—´: {total_time:.2f} ç§’")
        
        return results_file
    
    def _report_progress(self, episode: int):
        """æŠ¥å‘Šè¿›åº¦"""
        print(f"\nğŸ“Š Episode {episode} è¿›åº¦æŠ¥å‘Š:")
        
        for agent_name in self.agents.keys():
            rewards = self.results[agent_name]['rewards']
            success_rates = self.results[agent_name]['success_rates']
            
            if rewards:
                avg_reward = sum(rewards) / len(rewards)
                success_rate = sum(success_rates) / len(success_rates)
                
                print(f"  {agent_name}: å¹³å‡å¥–åŠ±={avg_reward:.3f}, æˆåŠŸç‡={success_rate:.3f}")
    
    def _final_analysis(self):
        """æœ€ç»ˆåˆ†æ"""
        print(f"\nğŸ¯ æœ€ç»ˆåˆ†æç»“æœ:")
        
        analysis = {}
        
        for agent_name in self.agents.keys():
            rewards = self.results[agent_name]['rewards']
            success_rates = self.results[agent_name]['success_rates']
            steps = self.results[agent_name]['steps']
            
            if rewards:
                analysis[agent_name] = {
                    'avg_reward': sum(rewards) / len(rewards),
                    'success_rate': sum(success_rates) / len(success_rates),
                    'avg_steps': sum(steps) / len(steps),
                    'total_episodes': len(rewards),
                    'best_reward': max(rewards),
                    'worst_reward': min(rewards),
                    'reward_std': np.std(rewards) if len(rewards) > 1 else 0
                }
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
        for agent_name, stats in analysis.items():
            print(f"\nğŸ¤– {agent_name.upper()}:")
            print(f"  - å¹³å‡å¥–åŠ±: {stats['avg_reward']:.3f} Â± {stats['reward_std']:.3f}")
            print(f"  - æˆåŠŸç‡: {stats['success_rate']:.3f}")
            print(f"  - å¹³å‡æ­¥æ•°: {stats['avg_steps']:.1f}")
            print(f"  - æœ€ä½³å¥–åŠ±: {stats['best_reward']:.3f}")
        
        # æ’å
        reward_ranking = sorted(analysis.items(), key=lambda x: x[1]['avg_reward'], reverse=True)
        success_ranking = sorted(analysis.items(), key=lambda x: x[1]['success_rate'], reverse=True)
        
        print(f"\nğŸ† æ€§èƒ½æ’å:")
        reward_str = ' > '.join([f'{name}({stats["avg_reward"]:.3f})' for name, stats in reward_ranking])
        success_str = ' > '.join([f'{name}({stats["success_rate"]:.3f})' for name, stats in success_ranking])
        print(f"ğŸ“Š æŒ‰å¹³å‡å¥–åŠ±: {reward_str}")
        print(f"ğŸ¯ æŒ‰æˆåŠŸç‡: {success_str}")
        
        self.final_analysis = analysis
    
    def _save_results(self) -> str:
        """ä¿å­˜å®éªŒç»“æœ"""
        results_dir = Path("experiments/results/baseline_comparison")
        results_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = int(time.time())
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results = {
            'experiment_config': self.experiment_config,
            'results': self.results,
            'final_analysis': getattr(self, 'final_analysis', {}),
            'agent_statistics': {name: agent.get_statistics() for name, agent in self.agents.items()},
            'timestamp': timestamp
        }
        
        results_file = results_dir / f"complete_baseline_experiment_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœä¿å­˜åˆ°: {results_file}")
        return str(results_file)
    
    def _generate_visualizations(self, results_file: str):
        """ç”Ÿæˆå¯è§†åŒ–"""
        print("ğŸ“Š ç”Ÿæˆå®éªŒå¯è§†åŒ–...")
        
        try:
            visualizer = ExperimentVisualizer()
            visualizer.generate_experiment_report(results_file)
        except Exception as e:
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å®Œæ•´åŸºçº¿å¯¹æ¯”å®éªŒ")
    
    # LLM APIé…ç½®
    api_key = "sk-rvwMvUNbWBz9L76KB05650C7Cc464324BdC98dB3FbD4296a"
    
    # åˆ›å»ºå®éªŒ
    experiment = CompleteBaselineExperiment(
        api_key=api_key,
        num_episodes=10,  # å‡å°‘episodeæ•°é‡ä»¥åŠ å¿«æµ‹è¯•
        max_steps=10      # å‡å°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
    )
    
    # è¿è¡Œå®éªŒ
    results_file = experiment.run_experiment()
    
    print(f"\nğŸ‰ å®éªŒå®Œæˆ! ç»“æœæ–‡ä»¶: {results_file}")


if __name__ == "__main__":
    # å¯¼å…¥numpyç”¨äºç»Ÿè®¡è®¡ç®—
    try:
        import numpy as np
    except ImportError:
        print("âš ï¸  numpyæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–ç»Ÿè®¡")
        class np:
            @staticmethod
            def std(x):
                if len(x) <= 1:
                    return 0
                mean = sum(x) / len(x)
                return (sum((xi - mean) ** 2 for xi in x) / len(x)) ** 0.5
    
    main()
