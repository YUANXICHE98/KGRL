#!/usr/bin/env python3
"""
æ ¼å¼è½¬æ¢å·¥å…· - è½¬æ¢å„ç§æ•°æ®æ ¼å¼
"""

import json
import yaml
import csv
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List

def json_to_yaml(input_file: Path, output_file: Path = None):
    """JSONè½¬YAML"""
    print(f"ğŸ”„ è½¬æ¢ {input_file.name} (JSON â†’ YAML)")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if output_file is None:
        output_file = input_file.with_suffix('.yaml')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
    
    print(f"  âœ… è¾“å‡º: {output_file}")
    return output_file

def yaml_to_json(input_file: Path, output_file: Path = None):
    """YAMLè½¬JSON"""
    print(f"ğŸ”„ è½¬æ¢ {input_file.name} (YAML â†’ JSON)")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)
    
    if output_file is None:
        output_file = input_file.with_suffix('.json')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… è¾“å‡º: {output_file}")
    return output_file

def results_to_csv(input_file: Path, output_file: Path = None):
    """å®éªŒç»“æœJSONè½¬CSV"""
    print(f"ğŸ“Š è½¬æ¢å®éªŒç»“æœ {input_file.name} (JSON â†’ CSV)")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if output_file is None:
        output_file = input_file.with_suffix('.csv')
    
    # æå–å®éªŒç»“æœæ•°æ®
    if 'results' in data:
        results_data = []
        
        for agent_name, agent_results in data['results'].items():
            if 'episode_details' in agent_results:
                for episode in agent_results['episode_details']:
                    row = {
                        'agent': agent_name,
                        'episode': episode.get('episode', 0),
                        'scene': episode.get('scene', ''),
                        'total_reward': episode.get('total_reward', 0),
                        'steps': episode.get('steps', 0),
                        'success': episode.get('success', False)
                    }
                    results_data.append(row)
        
        df = pd.DataFrame(results_data)
        df.to_csv(output_file, index=False)
        
        print(f"  âœ… è¾“å‡º: {output_file} ({len(results_data)} è¡Œ)")
    else:
        print(f"  âš ï¸ æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒè½¬æ¢")
    
    return output_file

def kg_to_graphml(input_file: Path, output_file: Path = None):
    """çŸ¥è¯†å›¾è°±JSONè½¬GraphML"""
    print(f"ğŸ•¸ï¸ è½¬æ¢çŸ¥è¯†å›¾è°± {input_file.name} (JSON â†’ GraphML)")
    
    try:
        import networkx as nx
    except ImportError:
        print("  âŒ éœ€è¦å®‰è£…networkx: pip install networkx")
        return None
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if output_file is None:
        output_file = input_file.with_suffix('.graphml')
    
    # åˆ›å»ºNetworkXå›¾
    G = nx.Graph()
    
    # æ·»åŠ èŠ‚ç‚¹
    if 'nodes' in data:
        for node in data['nodes']:
            node_id = node.get('id', '')
            G.add_node(node_id, **{k: v for k, v in node.items() if k != 'id'})
    
    # æ·»åŠ è¾¹
    if 'edges' in data:
        for edge in data['edges']:
            source = edge.get('source', '')
            target = edge.get('target', '')
            if source and target:
                G.add_edge(source, target, **{k: v for k, v in edge.items() 
                                            if k not in ['source', 'target']})
    
    # ä¿å­˜ä¸ºGraphML
    nx.write_graphml(G, output_file)
    
    print(f"  âœ… è¾“å‡º: {output_file} ({G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹)")
    return output_file

def batch_convert_directory(input_dir: Path, conversion_type: str):
    """æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„æ–‡ä»¶"""
    print(f"ğŸ“ æ‰¹é‡è½¬æ¢ç›®å½•: {input_dir}")
    print(f"ğŸ”„ è½¬æ¢ç±»å‹: {conversion_type}")
    
    conversion_map = {
        'json_to_yaml': (json_to_yaml, '*.json'),
        'yaml_to_json': (yaml_to_json, '*.yaml'),
        'results_to_csv': (results_to_csv, '*experiment*.json'),
        'kg_to_graphml': (kg_to_graphml, '*kg*.json')
    }
    
    if conversion_type not in conversion_map:
        print(f"  âŒ ä¸æ”¯æŒçš„è½¬æ¢ç±»å‹: {conversion_type}")
        return []
    
    convert_func, pattern = conversion_map[conversion_type]
    
    input_files = list(input_dir.glob(pattern))
    converted_files = []
    
    for input_file in input_files:
        try:
            output_file = convert_func(input_file)
            if output_file:
                converted_files.append(output_file)
        except Exception as e:
            print(f"  âŒ è½¬æ¢å¤±è´¥ {input_file.name}: {e}")
    
    print(f"  âœ… æˆåŠŸè½¬æ¢ {len(converted_files)} ä¸ªæ–‡ä»¶")
    return converted_files

def create_conversion_report(converted_files: List[Path], output_dir: Path):
    """åˆ›å»ºè½¬æ¢æŠ¥å‘Š"""
    print(f"\nğŸ“‹ åˆ›å»ºè½¬æ¢æŠ¥å‘Š...")
    
    report = {
        "conversion_time": __import__('datetime').datetime.now().isoformat(),
        "total_files": len(converted_files),
        "files": []
    }
    
    for file_path in converted_files:
        file_info = {
            "name": file_path.name,
            "size": file_path.stat().st_size,
            "path": str(file_path.relative_to(output_dir.parent))
        }
        report["files"].append(file_info)
    
    report_file = output_dir / "conversion_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… è½¬æ¢æŠ¥å‘Š: {report_file}")
    return report_file

def main():
    """ä¸»è½¬æ¢å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="KGRLæ ¼å¼è½¬æ¢å·¥å…·")
    parser.add_argument("--input", "-i", type=str, required=True,
                       help="è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("--output", "-o", type=str,
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--type", "-t", type=str, required=True,
                       choices=['json_to_yaml', 'yaml_to_json', 'results_to_csv', 
                               'kg_to_graphml', 'batch'],
                       help="è½¬æ¢ç±»å‹")
    parser.add_argument("--batch-type", type=str,
                       choices=['json_to_yaml', 'yaml_to_json', 'results_to_csv', 
                               'kg_to_graphml'],
                       help="æ‰¹é‡è½¬æ¢æ—¶çš„å…·ä½“ç±»å‹")
    
    args = parser.parse_args()
    
    print("ğŸ”„ KGRLæ ¼å¼è½¬æ¢å·¥å…·")
    print("=" * 30)
    
    input_path = Path(args.input)
    
    if not input_path.exists():
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return
    
    output_path = Path(args.output) if args.output else None
    
    try:
        if args.type == 'batch':
            if not args.batch_type:
                print("âŒ æ‰¹é‡è½¬æ¢éœ€è¦æŒ‡å®š --batch-type")
                return
            
            if input_path.is_dir():
                converted_files = batch_convert_directory(input_path, args.batch_type)
                create_conversion_report(converted_files, input_path)
            else:
                print("âŒ æ‰¹é‡è½¬æ¢éœ€è¦è¾“å…¥ç›®å½•")
        else:
            # å•æ–‡ä»¶è½¬æ¢
            conversion_map = {
                'json_to_yaml': json_to_yaml,
                'yaml_to_json': yaml_to_json,
                'results_to_csv': results_to_csv,
                'kg_to_graphml': kg_to_graphml
            }
            
            convert_func = conversion_map[args.type]
            result = convert_func(input_path, output_path)
            
            if result:
                print(f"\nâœ… è½¬æ¢å®Œæˆ: {result}")
            else:
                print(f"\nâŒ è½¬æ¢å¤±è´¥")
    
    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
