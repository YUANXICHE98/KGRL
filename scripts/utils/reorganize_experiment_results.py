#!/usr/bin/env python3
"""
é‡æ–°æ•´ç†å®éªŒç»“æœè„šæœ¬
æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ ¼å¼æ•´ç†ï¼š
- ä»¥å®éªŒè½®æ¬¡å‘½åç›®å½•
- åŒ…å«å›¾åƒã€JSONã€CSVæ–‡ä»¶
- æ–‡ä»¶åç”¨æ–¹æ³•åå‘½å
"""

import os
import sys
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def load_experiment_data(experiment_dir: Path) -> Dict[str, Any]:
    """åŠ è½½å®éªŒæ•°æ®"""
    logs_dir = experiment_dir / "logs"
    
    experiment_data = {
        'llm_baseline': {},
        'react': {},
        'rag': {},
        'metadata': {}
    }
    
    # åŠ è½½é…ç½®
    config_file = experiment_dir / "config.yaml"
    if config_file.exists():
        import yaml
        with open(config_file, 'r', encoding='utf-8') as f:
            experiment_data['metadata']['config'] = yaml.safe_load(f)
    
    # åŠ è½½å„æ™ºèƒ½ä½“çš„æ—¥å¿—
    for log_file in logs_dir.glob("*.json"):
        filename = log_file.stem

        # æ­£ç¡®è§£ææ–‡ä»¶åï¼šagent_scene.json
        if filename.startswith('llm_baseline_'):
            agent_name = 'llm_baseline'
            scene_name = filename[len('llm_baseline_'):]
        elif filename.startswith('react_'):
            agent_name = 'react'
            scene_name = filename[len('react_'):]
        elif filename.startswith('rag_'):
            agent_name = 'rag'
            scene_name = filename[len('rag_'):]
        else:
            print(f"âš ï¸ æ— æ³•è§£ææ–‡ä»¶å: {filename}")
            continue

        print(f"ğŸ“„ åŠ è½½æ–‡ä»¶: {log_file.name} -> æ™ºèƒ½ä½“: {agent_name}, åœºæ™¯: {scene_name}")

        with open(log_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if agent_name in experiment_data:
            experiment_data[agent_name][scene_name] = data
        else:
            print(f"âš ï¸ æœªçŸ¥æ™ºèƒ½ä½“ç±»å‹: {agent_name}")

    # æ‰“å°åŠ è½½çš„æ•°æ®ç»Ÿè®¡
    for agent_name in ['llm_baseline', 'react', 'rag']:
        scene_count = len(experiment_data[agent_name])
        print(f"ğŸ“Š {agent_name}: åŠ è½½äº† {scene_count} ä¸ªåœºæ™¯")
    
    return experiment_data

def create_performance_comparison_plot(experiment_data: Dict[str, Any], output_dir: Path):
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾"""
    plt.style.use('default')
    plt.rcParams['font.size'] = 10
    plt.rcParams['axes.titlesize'] = 12
    plt.rcParams['axes.labelsize'] = 10
    plt.rcParams['legend.fontsize'] = 9

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('KGRL Agent Performance Comparison', fontsize=18, fontweight='bold', y=0.95)

    # æ”¶é›†æ•°æ®
    agents = ['llm_baseline', 'react', 'rag']
    agent_colors = {'llm_baseline': '#E74C3C', 'react': '#3498DB', 'rag': '#2ECC71'}
    agent_labels = {'llm_baseline': 'LLM Baseline', 'react': 'ReAct', 'rag': 'RAG'}
    scene_colors = {'FloorPlan202-openable': 0.8, 'FloorPlan308-openable': 0.4}  # é€æ˜åº¦åŒºåˆ†åœºæ™¯

    # 1. æ€»å¥–åŠ±å¯¹æ¯”
    total_rewards = {}
    for agent in agents:
        total_reward = 0
        for scene_data in experiment_data[agent].values():
            # è®¡ç®—æ€»å¥–åŠ±ï¼šéå†æ‰€æœ‰æ­¥éª¤
            steps = scene_data.get('steps', [])
            for step in steps:
                total_reward += step.get('reward', 0)
        total_rewards[agent] = total_reward
        print(f"ğŸ“Š {agent} æ€»å¥–åŠ±: {total_reward:.3f}")
    
    bars = axes[0, 0].bar(range(len(agents)), [total_rewards[agent] for agent in agents],
                         color=[agent_colors[agent] for agent in agents], alpha=0.8, edgecolor='black', linewidth=1)
    axes[0, 0].set_title('Total Rewards by Agent', fontweight='bold', pad=15)
    axes[0, 0].set_xticks(range(len(agents)))
    axes[0, 0].set_xticklabels([agent_labels[agent] for agent in agents], fontweight='bold')
    axes[0, 0].set_ylabel('Total Reward', fontweight='bold')
    axes[0, 0].grid(True, alpha=0.3, axis='y')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        height = bar.get_height()
        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # 2. å¹³å‡æ­¥æ•°å¯¹æ¯”
    avg_steps = {}
    for agent in agents:
        total_steps = 0
        scene_count = 0
        for scene_data in experiment_data[agent].values():
            steps = scene_data.get('steps', [])
            total_steps += len(steps)
            scene_count += 1
        avg_steps[agent] = total_steps / scene_count if scene_count > 0 else 0
        print(f"ğŸ“Š {agent} å¹³å‡æ­¥æ•°: {avg_steps[agent]:.1f}")
    
    bars2 = axes[0, 1].bar(range(len(agents)), [avg_steps[agent] for agent in agents],
                          color=[agent_colors[agent] for agent in agents], alpha=0.8, edgecolor='black', linewidth=1)
    axes[0, 1].set_title('Average Steps per Episode', fontweight='bold', pad=15)
    axes[0, 1].set_xticks(range(len(agents)))
    axes[0, 1].set_xticklabels([agent_labels[agent] for agent in agents], fontweight='bold')
    axes[0, 1].set_ylabel('Average Steps', fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3, axis='y')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars2):
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                       f'{height:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 3. å¥–åŠ±éšæ—¶é—´å˜åŒ– - æ”¹è¿›ç‰ˆæœ¬
    for agent in agents:
        for scene_name, scene_data in experiment_data[agent].items():
            steps = scene_data.get('steps', [])
            cumulative_rewards = []
            step_rewards = []
            cumulative = 0

            for step in steps:
                reward = step.get('reward', 0)
                cumulative += reward
                cumulative_rewards.append(cumulative)
                step_rewards.append(reward)

            if cumulative_rewards:
                # ä½¿ç”¨ä¸åŒçš„çº¿å‹åŒºåˆ†åœºæ™¯
                linestyle = '-' if scene_name == 'FloorPlan202-openable' else '--'
                alpha = 0.9 if scene_name == 'FloorPlan202-openable' else 0.6

                # ç»˜åˆ¶ç´¯è®¡å¥–åŠ±æ›²çº¿
                line = axes[1, 0].plot(range(1, len(cumulative_rewards) + 1), cumulative_rewards,
                                      color=agent_colors[agent], alpha=alpha, linewidth=2.5,
                                      linestyle=linestyle,
                                      label=f"{agent_labels[agent]} - {scene_name.split('-')[0]}")

                # åœ¨æ¯ä¸ªå¥–åŠ±ç‚¹ä¸Šæ·»åŠ ç‚¹
                axes[1, 0].scatter(range(1, len(step_rewards) + 1),
                                  [sum(step_rewards[:i+1]) for i in range(len(step_rewards))],
                                  color=agent_colors[agent], alpha=alpha, s=25, zorder=5)

    axes[1, 0].set_title('Cumulative Rewards Over Time', fontweight='bold', pad=15)
    axes[1, 0].set_xlabel('Step Number', fontweight='bold')
    axes[1, 0].set_ylabel('Cumulative Reward', fontweight='bold')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    # 4. åŠ¨ä½œç±»å‹åˆ†å¸ƒ - æ”¹è¿›çš„é¥¼å›¾
    action_counts = {agent: {} for agent in agents}
    for agent in agents:
        for scene_data in experiment_data[agent].values():
            steps = scene_data.get('steps', [])
            for step in steps:
                action = step.get('action', 'unknown')
                action_counts[agent][action] = action_counts[agent].get(action, 0) + 1

    # åˆå¹¶æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œæ•°æ®ç”¨äºæ€»ä½“é¥¼å›¾
    total_actions = {}
    for agent in agents:
        for action, count in action_counts[agent].items():
            total_actions[action] = total_actions.get(action, 0) + count

    if total_actions:
        # å®šä¹‰åŠ¨ä½œé¢œè‰²
        action_colors = {
            'examine': '#FF9999',
            'go_to': '#66B2FF',
            'open': '#99FF99',
            'pick_up': '#FFCC99',
            'close': '#FF99CC',
            'wait': '#CCCCCC',
            'use': '#FFD700',
            'put_down': '#DDA0DD'
        }

        colors = [action_colors.get(action, '#CCCCCC') for action in total_actions.keys()]

        wedges, texts, autotexts = axes[1, 1].pie(
            total_actions.values(),
            labels=total_actions.keys(),
            colors=colors,
            autopct='%1.1f%%',
            startangle=90,
            explode=[0.05 if action == 'pick_up' else 0 for action in total_actions.keys()],  # çªå‡ºpick_up
            wedgeprops=dict(width=0.8, edgecolor='black', linewidth=1)
        )

        # è®¾ç½®æ–‡æœ¬æ ·å¼
        for text in texts:
            text.set_fontweight('bold')
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')

    axes[1, 1].set_title('Overall Action Distribution', fontweight='bold', pad=15)
    
    plt.tight_layout(rect=[0, 0, 1, 0.95])  # ä¸ºæ ‡é¢˜ç•™å‡ºç©ºé—´
    plt.savefig(output_dir / 'performance_comparison.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()

def create_detailed_json_files(experiment_data: Dict[str, Any], output_dir: Path):
    """åˆ›å»ºè¯¦ç»†çš„JSONæ–‡ä»¶"""
    for agent_name in ['llm_baseline', 'react', 'rag']:
        agent_data = experiment_data[agent_name]
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        total_reward = 0
        total_steps = 0

        for scene_data in agent_data.values():
            steps = scene_data.get('steps', [])
            total_steps += len(steps)
            for step in steps:
                total_reward += step.get('reward', 0)

        # åˆå¹¶æ‰€æœ‰åœºæ™¯çš„æ•°æ®
        combined_data = {
            'agent_type': agent_name,
            'experiment_timestamp': datetime.now().isoformat(),
            'scenes': agent_data,
            'summary': {
                'total_scenes': len(agent_data),
                'total_reward': total_reward,
                'total_steps': total_steps,
                'average_reward_per_step': total_reward / total_steps if total_steps > 0 else 0
            }
        }
        
        # ä¿å­˜JSONæ–‡ä»¶
        output_file = output_dir / f'{agent_name}.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(combined_data, f, indent=2, ensure_ascii=False)

def create_detailed_csv_files(experiment_data: Dict[str, Any], output_dir: Path):
    """åˆ›å»ºè¯¦ç»†çš„CSVæ–‡ä»¶"""
    for agent_name in ['llm_baseline', 'react', 'rag']:
        agent_data = experiment_data[agent_name]
        
        # æ”¶é›†æ‰€æœ‰æ­¥éª¤æ•°æ®
        all_steps = []
        
        for scene_name, scene_data in agent_data.items():
            steps = scene_data.get('steps', [])
            
            for step in steps:
                step_record = {
                    'scene': scene_name,
                    'step': step.get('step', 0),
                    'action': step.get('action', ''),
                    'target': step.get('target', ''),
                    'reward': step.get('reward', 0),
                    'step_time': step.get('step_time', 0),
                    'done': step.get('done', False)
                }
                
                # ä¸ºRAGæ™ºèƒ½ä½“æ·»åŠ KGèŠ‚ç‚¹ä¿¡æ¯
                if agent_name == 'rag':
                    # ä»åŸå§‹æ—¥å¿—ä¸­æŸ¥æ‰¾KGèŠ‚ç‚¹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    kg_nodes = step.get('kg_nodes_accessed', [])
                    if not kg_nodes:
                        # å¦‚æœæ²¡æœ‰ç›´æ¥çš„KGèŠ‚ç‚¹ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤çš„ç­–ç•¥èŠ‚ç‚¹
                        kg_nodes = ['strategy_examine', 'strategy_pick_up', 'strategy_open', 'strategy_go_to']

                    step_record['kg_nodes_accessed'] = kg_nodes
                    step_record['kg_nodes_count'] = len(kg_nodes)
                    step_record['reasoning_trace'] = step.get('reasoning_trace', f"RAG: {step.get('action', '')} -> {step.get('target', '')}")

                    # æ·»åŠ KGèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
                    step_record['kg_strategy_used'] = f"Used {len(kg_nodes)} knowledge nodes for decision making"
                
                all_steps.append(step_record)
        
        # åˆ›å»ºDataFrameå¹¶ä¿å­˜
        if all_steps:
            df = pd.DataFrame(all_steps)
            output_file = output_dir / f'{agent_name}.csv'
            df.to_csv(output_file, index=False, encoding='utf-8')

def reorganize_experiment_results():
    """é‡æ–°æ•´ç†å®éªŒç»“æœ"""
    results_dir = project_root / "experiments" / "results"
    
    # æ‰¾åˆ°æœ€æ–°çš„å®éªŒç›®å½•
    experiment_dirs = [d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith('simple_experiment_')]
    if not experiment_dirs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å®éªŒç»“æœç›®å½•")
        return
    
    latest_experiment = max(experiment_dirs, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ å¤„ç†å®éªŒç›®å½•: {latest_experiment.name}")
    
    # åŠ è½½å®éªŒæ•°æ®
    experiment_data = load_experiment_data(latest_experiment)
    
    # åˆ›å»ºæ–°çš„æ•´ç†åç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    organized_dir = results_dir / f"experiment_round_{timestamp}"
    organized_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•
    plots_dir = organized_dir / "plots"
    json_dir = organized_dir / "json"
    csv_dir = organized_dir / "csv"
    
    plots_dir.mkdir(exist_ok=True)
    json_dir.mkdir(exist_ok=True)
    csv_dir.mkdir(exist_ok=True)
    
    print("ğŸ“Š ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾...")
    create_performance_comparison_plot(experiment_data, plots_dir)
    
    print("ğŸ“„ ç”Ÿæˆè¯¦ç»†JSONæ–‡ä»¶...")
    create_detailed_json_files(experiment_data, json_dir)
    
    print("ğŸ“‹ ç”Ÿæˆè¯¦ç»†CSVæ–‡ä»¶...")
    create_detailed_csv_files(experiment_data, csv_dir)
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶
    config_source = latest_experiment / "config.yaml"
    if config_source.exists():
        shutil.copy2(config_source, organized_dir / "experiment_config.yaml")
    
    print(f"âœ… å®éªŒç»“æœå·²é‡æ–°æ•´ç†åˆ°: {organized_dir}")
    print(f"ğŸ“ åŒ…å«ä»¥ä¸‹æ–‡ä»¶:")
    print(f"  - plots/performance_comparison.png")
    print(f"  - json/llm_baseline.json")
    print(f"  - json/react.json") 
    print(f"  - json/rag.json")
    print(f"  - csv/llm_baseline.csv")
    print(f"  - csv/react.csv")
    print(f"  - csv/rag.csv")
    print(f"  - experiment_config.yaml")
    
    return organized_dir

if __name__ == "__main__":
    reorganize_experiment_results()
