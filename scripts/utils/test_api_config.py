#!/usr/bin/env python3
"""
æµ‹è¯•APIé…ç½®è„šæœ¬
éªŒè¯VimsAI APIè¿æ¥å’Œå¯ç”¨æ¨¡å‹
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.utils.simple_config import get_config

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("ğŸ§ª æµ‹è¯•VimsAI APIé…ç½®")
    print("=" * 50)
    
    # è·å–é…ç½®
    config = get_config()
    api_key = config.get_api_key()
    base_url = config.get_base_url()
    model = config.get('llm.model')
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - APIå¯†é’¥: {api_key[:10]}...{api_key[-4:]}")
    print(f"  - Base URL: {base_url}")
    print(f"  - æ¨¡å‹: {model}")
    print()
    
    # æµ‹è¯•APIè¿æ¥
    try:
        from openai import OpenAI
        
        print("ğŸ”— æµ‹è¯•APIè¿æ¥...")
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        # å‘é€æµ‹è¯•è¯·æ±‚
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Hello! Please respond with 'API connection successful' if you can see this message."}
            ],
            max_tokens=50,
            temperature=0.1
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ… APIè¿æ¥æˆåŠŸ!")
        print(f"ğŸ“ å“åº”: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        
        # å°è¯•å¤‡ç”¨URL
        print("\nğŸ”„ å°è¯•å¤‡ç”¨URL...")
        try:
            backup_url = "https://usa.vimsai.com/v1"
            print(f"  - å¤‡ç”¨URL: {backup_url}")
            
            client = OpenAI(
                api_key=api_key,
                base_url=backup_url
            )
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello! Please respond with 'Backup API connection successful' if you can see this message."}
                ],
                max_tokens=50,
                temperature=0.1
            )
            
            result = response.choices[0].message.content.strip()
            print(f"âœ… å¤‡ç”¨APIè¿æ¥æˆåŠŸ!")
            print(f"ğŸ“ å“åº”: {result}")
            
            # æ›´æ–°é…ç½®æ–‡ä»¶ä½¿ç”¨å¤‡ç”¨URL
            print(f"ğŸ”§ æ›´æ–°é…ç½®æ–‡ä»¶ä½¿ç”¨å¤‡ç”¨URL...")
            config.set('llm.base_url', backup_url)
            config.save()
            
            return True
            
        except Exception as backup_e:
            print(f"âŒ å¤‡ç”¨APIä¹Ÿè¿æ¥å¤±è´¥: {backup_e}")
            return False

def test_different_models():
    """æµ‹è¯•ä¸åŒæ¨¡å‹"""
    print("\nğŸ¯ æµ‹è¯•ä¸åŒæ¨¡å‹...")
    print("=" * 50)
    
    config = get_config()
    api_key = config.get_api_key()
    base_url = config.get_base_url()
    
    # å¸¸è§çš„VimsAIæ”¯æŒçš„æ¨¡å‹
    models_to_test = [
        "claude-3-5-sonnet-20241022",
        "claude-3-haiku-20240307", 
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-3.5-turbo"
    ]
    
    working_models = []
    
    for model in models_to_test:
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model}")
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": "Hi"}
                ],
                max_tokens=10,
                temperature=0.1
            )
            
            result = response.choices[0].message.content.strip()
            print(f"  âœ… {model}: {result}")
            working_models.append(model)
            
        except Exception as e:
            print(f"  âŒ {model}: {str(e)[:100]}...")
    
    print(f"\nğŸ“Š å¯ç”¨æ¨¡å‹æ€»ç»“:")
    print(f"  - æ€»æµ‹è¯•: {len(models_to_test)} ä¸ª")
    print(f"  - å¯ç”¨: {len(working_models)} ä¸ª")
    
    if working_models:
        print(f"  - æ¨èæ¨¡å‹: {working_models[0]}")
        
        # æ›´æ–°é…ç½®ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
        if working_models[0] != config.get('llm.model'):
            print(f"ğŸ”§ æ›´æ–°é…ç½®ä½¿ç”¨æ¨èæ¨¡å‹: {working_models[0]}")
            config.set('llm.model', working_models[0])
            config.save()
    
    return working_models

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ VimsAI APIé…ç½®æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•åŸºæœ¬è¿æ¥
    connection_ok = test_api_connection()
    
    if connection_ok:
        # æµ‹è¯•ä¸åŒæ¨¡å‹
        working_models = test_different_models()
        
        print(f"\nğŸ‰ é…ç½®æµ‹è¯•å®Œæˆ!")
        print(f"âœ… APIè¿æ¥æ­£å¸¸")
        print(f"âœ… æ‰¾åˆ° {len(working_models)} ä¸ªå¯ç”¨æ¨¡å‹")
        print(f"ğŸ”§ é…ç½®å·²è‡ªåŠ¨ä¼˜åŒ–")
        
    else:
        print(f"\nâŒ é…ç½®æµ‹è¯•å¤±è´¥!")
        print(f"è¯·æ£€æŸ¥:")
        print(f"  1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print(f"  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸") 
        print(f"  3. VimsAIæœåŠ¡æ˜¯å¦å¯ç”¨")

if __name__ == "__main__":
    main()
