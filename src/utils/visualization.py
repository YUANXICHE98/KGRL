#!/usr/bin/env python3
"""
å®éªŒç»“æœå¯è§†åŒ–å·¥å…·
"""

import json
import time
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, List
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®è‹±æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.family'] = 'Arial'
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®æ ·å¼
sns.set_style("whitegrid")
plt.style.use('seaborn-v0_8')


class ExperimentVisualizer:
    """å®éªŒç»“æœå¯è§†åŒ–å™¨"""
    
    def __init__(self, results_dir: str = "experiments/results"):
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå›¾è¡¨ä¿å­˜ç›®å½•
        self.plots_dir = self.results_dir / "plots"
        self.plots_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“Š åˆå§‹åŒ–å®éªŒå¯è§†åŒ–å™¨ (ç»“æœç›®å½•: {results_dir})")
    
    def plot_baseline_comparison(self, results_file: str) -> None:
        """Plot baseline comparison charts"""
        # Load results
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        results = data['results']
        final_analysis = data.get('final_analysis', {})

        # Create subplots
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Baseline Agent Comparison Results', fontsize=16, fontweight='bold')
        
        # 1. Average Reward Comparison
        agents = list(final_analysis.keys())
        avg_rewards = [final_analysis[agent]['avg_reward'] for agent in agents]

        axes[0, 0].bar(agents, avg_rewards, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[0, 0].set_title('Average Reward Comparison')
        axes[0, 0].set_ylabel('Average Reward')
        axes[0, 0].tick_params(axis='x', rotation=45)

        # Add value labels
        for i, v in enumerate(avg_rewards):
            axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')

        # 2. Success Rate Comparison
        success_rates = [final_analysis[agent]['success_rate'] for agent in agents]

        axes[0, 1].bar(agents, success_rates, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[0, 1].set_title('Success Rate Comparison')
        axes[0, 1].set_ylabel('Success Rate')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].set_ylim(0, 1)

        # Add value labels
        for i, v in enumerate(success_rates):
            axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')

        # 3. Average Steps Comparison
        avg_steps = [final_analysis[agent]['avg_steps'] for agent in agents]

        axes[1, 0].bar(agents, avg_steps, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[1, 0].set_title('Average Steps Comparison (Lower is Better)')
        axes[1, 0].set_ylabel('Average Steps')
        axes[1, 0].tick_params(axis='x', rotation=45)

        # Add value labels
        for i, v in enumerate(avg_steps):
            axes[1, 0].text(i, v + 0.5, f'{v:.1f}', ha='center', va='bottom')

        # 4. Reward Distribution Box Plot
        reward_data = []
        agent_labels = []

        for agent in agents:
            rewards = results[agent]['rewards']
            reward_data.extend(rewards)
            agent_labels.extend([agent] * len(rewards))

        df = pd.DataFrame({'Agent': agent_labels, 'Reward': reward_data})
        sns.boxplot(data=df, x='Agent', y='Reward', ax=axes[1, 1])
        axes[1, 1].set_title('Reward Distribution')
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()

        # Save chart with standardized naming
        timestamp = int(time.time())
        plot_file = self.plots_dir / f"baseline_comparison_{timestamp}.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Baseline comparison chart saved to: {plot_file}")

        plt.close()  # Close instead of show for batch processing
    
    def plot_learning_curves(self, results_file: str) -> None:
        """Plot learning curves with English labels"""
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        results = data['results']

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle('Learning Curves', fontsize=16, fontweight='bold')
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        
        for i, (agent, agent_results) in enumerate(results.items()):
            episodes = range(1, len(agent_results['rewards']) + 1)
            
            # 1. å¥–åŠ±æ›²çº¿
            axes[0].plot(episodes, agent_results['rewards'], 
                        label=agent, color=colors[i % len(colors)], alpha=0.7)
            
            # æ·»åŠ ç§»åŠ¨å¹³å‡
            if len(agent_results['rewards']) > 5:
                window = min(5, len(agent_results['rewards']) // 4)
                moving_avg = pd.Series(agent_results['rewards']).rolling(window=window).mean()
                axes[0].plot(episodes, moving_avg, 
                           color=colors[i % len(colors)], linewidth=2)
            
            # 2. æˆåŠŸç‡æ›²çº¿
            axes[1].plot(episodes, agent_results['success_rates'], 
                        label=agent, color=colors[i % len(colors)], alpha=0.7)
            
            # 3. æ­¥æ•°æ›²çº¿
            axes[2].plot(episodes, agent_results['steps'], 
                        label=agent, color=colors[i % len(colors)], alpha=0.7)
        
        axes[0].set_title('Reward Progress')
        axes[0].set_xlabel('Episode')
        axes[0].set_ylabel('Reward')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        axes[1].set_title('Success Rate Progress')
        axes[1].set_xlabel('Episode')
        axes[1].set_ylabel('Success Rate')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        axes[2].set_title('Steps Progress')
        axes[2].set_xlabel('Episode')
        axes[2].set_ylabel('Steps')
        axes[2].legend()
        axes[2].grid(True, alpha=0.3)

        plt.tight_layout()

        # Save chart with standardized naming
        timestamp = int(time.time())
        plot_file = self.plots_dir / f"learning_curves_{timestamp}.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ Learning curves saved to: {plot_file}")

        plt.close()  # Close instead of show
    
    def plot_performance_radar(self, results_file: str) -> None:
        """ç»˜åˆ¶æ€§èƒ½é›·è¾¾å›¾"""
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        final_analysis = data.get('final_analysis', {})
        
        if not final_analysis:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ€ç»ˆåˆ†ææ•°æ®")
            return
        
        # å‡†å¤‡æ•°æ®
        agents = list(final_analysis.keys())
        metrics = ['avg_reward', 'success_rate', 'efficiency']  # efficiency = 1 / avg_steps
        
        # æ ‡å‡†åŒ–æ•°æ®åˆ°0-1èŒƒå›´
        values = []
        for agent in agents:
            agent_data = final_analysis[agent]
            efficiency = 1.0 / max(agent_data['avg_steps'], 1)  # æ­¥æ•°è¶Šå°‘æ•ˆç‡è¶Šé«˜
            
            agent_values = [
                agent_data['avg_reward'] / 10.0,  # å‡è®¾æœ€å¤§å¥–åŠ±ä¸º10
                agent_data['success_rate'],
                efficiency * 10  # è°ƒæ•´æ•ˆç‡æ¯”ä¾‹
            ]
            values.append(agent_values)
        
        # åˆ›å»ºé›·è¾¾å›¾
        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆå›¾å½¢
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        
        for i, (agent, agent_values) in enumerate(zip(agents, values)):
            agent_values += agent_values[:1]  # é—­åˆæ•°æ®
            ax.plot(angles, agent_values, 'o-', linewidth=2, 
                   label=agent, color=colors[i % len(colors)])
            ax.fill(angles, agent_values, alpha=0.25, color=colors[i % len(colors)])
        
        # è®¾ç½®æ ‡ç­¾
        metric_labels = ['å¹³å‡å¥–åŠ±', 'æˆåŠŸç‡', 'æ•ˆç‡']
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metric_labels)
        ax.set_ylim(0, 1)
        ax.set_title('æ™ºèƒ½ä½“æ€§èƒ½é›·è¾¾å›¾', size=16, fontweight='bold', pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plot_file = self.plots_dir / "performance_radar.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ¯ æ€§èƒ½é›·è¾¾å›¾ä¿å­˜åˆ°: {plot_file}")
        
        plt.show()
    
    def generate_experiment_report(self, results_file: str) -> str:
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        print("ğŸ“Š ç”Ÿæˆå®éªŒå›¾è¡¨...")
        self.plot_baseline_comparison(results_file)
        self.plot_learning_curves(results_file)
        self.plot_performance_radar(results_file)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = self.results_dir / "experiment_report.md"
        
        final_analysis = data.get('final_analysis', {})
        config = data.get('experiment_config', {})
        
        report_content = f"""# åŸºçº¿æ™ºèƒ½ä½“å¯¹æ¯”å®éªŒæŠ¥å‘Š

## å®éªŒé…ç½®
- **Episodes**: {config.get('num_episodes', 'N/A')}
- **æœ€å¤§æ­¥æ•°**: {config.get('max_steps', 'N/A')}
- **æ™ºèƒ½ä½“ç±»å‹**: {', '.join(data['results'].keys())}

## å®éªŒç»“æœ

### æ€§èƒ½å¯¹æ¯”
"""
        
        if final_analysis:
            for agent, stats in final_analysis.items():
                report_content += f"""
#### {agent.upper()}
- å¹³å‡å¥–åŠ±: {stats['avg_reward']:.3f}
- æˆåŠŸç‡: {stats['success_rate']:.3f}
- å¹³å‡æ­¥æ•°: {stats['avg_steps']:.1f}
- æœ€ä½³å¥–åŠ±: {stats['best_reward']:.3f}
"""
        
        report_content += f"""
## å¯è§†åŒ–ç»“æœ

### å›¾è¡¨æ–‡ä»¶
- åŸºçº¿å¯¹æ¯”å›¾: `plots/baseline_comparison.png`
- å­¦ä¹ æ›²çº¿: `plots/learning_curves.png`
- æ€§èƒ½é›·è¾¾å›¾: `plots/performance_radar.png`

## ç»“è®º

åŸºäºå®éªŒç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

1. **æ€§èƒ½æ’å**: æ ¹æ®å¹³å‡å¥–åŠ±æ’åº
2. **å­¦ä¹ æ•ˆç‡**: åˆ†æå­¦ä¹ æ›²çº¿çš„æ”¶æ•›é€Ÿåº¦
3. **ç¨³å®šæ€§**: åŸºäºå¥–åŠ±æ–¹å·®è¯„ä¼°ç¨³å®šæ€§

## ä¸‹ä¸€æ­¥å·¥ä½œ

1. å¢åŠ æ›´å¤šåœºæ™¯æµ‹è¯•
2. ä¼˜åŒ–æ™ºèƒ½ä½“ç­–ç•¥
3. å¼•å…¥çŸ¥è¯†å›¾è°±å¢å¼º
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ å®éªŒæŠ¥å‘Šä¿å­˜åˆ°: {report_file}")
        return str(report_file)


if __name__ == "__main__":
    # æµ‹è¯•å¯è§†åŒ–å·¥å…·
    print("ğŸ§ª æµ‹è¯•å®éªŒå¯è§†åŒ–å·¥å…·")
    
    visualizer = ExperimentVisualizer()
    
    # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
    results_dir = Path("experiments/results/baseline_comparison")
    if results_dir.exists():
        result_files = list(results_dir.glob("baseline_comparison_*.json"))
        if result_files:
            latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
            print(f"ğŸ“Š å¤„ç†ç»“æœæ–‡ä»¶: {latest_file}")
            
            # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
            visualizer.generate_experiment_report(str(latest_file))
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç»“æœæ–‡ä»¶")
    else:
        print("âŒ ç»“æœç›®å½•ä¸å­˜åœ¨")
    
    print("âœ… æµ‹è¯•å®Œæˆ")
