#!/usr/bin/env python3
"""
LLMå®¢æˆ·ç«¯
æ”¯æŒå¤šç§LLM APIè°ƒç”¨
"""

import json
import requests
import time
from typing import Dict, Any, List, Optional
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


class LLMClient:
    """LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://vir.vimsai.com", model: str = "gpt-4o"):
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        print(f"ğŸ¤– åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ (æ¨¡å‹: {model})")
    
    def chat_completion(self, messages: List[Dict[str, str]], 
                       temperature: float = 0.7, max_tokens: int = 512) -> str:
        """èŠå¤©å®Œæˆ"""
        try:
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content'].strip()
            else:
                print(f"âŒ LLM APIé”™è¯¯: {response.status_code} - {response.text}")
                return self._fallback_response(messages)
                
        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¼‚å¸¸: {e}")
            return self._fallback_response(messages)
    
    def _fallback_response(self, messages: List[Dict[str, str]]) -> str:
        """å¤‡ç”¨å“åº”"""
        last_message = messages[-1]['content'] if messages else ""
        
        # ç®€å•çš„è§„åˆ™å¤‡ç”¨
        if "pick up" in last_message.lower():
            return "pick_up"
        elif "open" in last_message.lower():
            return "open"
        elif "go to" in last_message.lower():
            return "go_to"
        elif "examine" in last_message.lower():
            return "examine"
        else:
            return "wait"


class LLMBaselineAgent:
    """çœŸæ­£çš„LLMåŸºçº¿æ™ºèƒ½ä½“"""
    
    def __init__(self, api_key: str):
        self.llm_client = LLMClient(api_key)
        self.conversation_history = []
        self.max_history = 5
        
        print("ğŸ¤– åˆå§‹åŒ–çœŸæ­£çš„LLMåŸºçº¿æ™ºèƒ½ä½“")
    
    def reset(self, scene_info: Dict[str, Any] = None):
        """é‡ç½®æ™ºèƒ½ä½“"""
        self.conversation_history = []
        if scene_info:
            self.conversation_history.append({
                "role": "system",
                "content": f"ä½ æ˜¯ä¸€ä¸ªåœ¨{scene_info.get('scene', 'æœªçŸ¥åœºæ™¯')}ä¸­çš„æ™ºèƒ½ä½“ã€‚ä½ çš„ç›®æ ‡æ˜¯å®Œæˆä»»åŠ¡ã€‚"
            })
    
    def select_action(self, observation: Dict[str, Any]) -> tuple[str, str]:
        """é€‰æ‹©åŠ¨ä½œ"""
        # æ„å»ºæç¤º
        prompt = self._build_prompt(observation)
        
        # æ·»åŠ åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "user", 
            "content": prompt
        })
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_history * 2:
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„å¯¹è¯
            system_msg = self.conversation_history[0] if self.conversation_history[0]["role"] == "system" else None
            recent_msgs = self.conversation_history[-(self.max_history * 2 - 1):]
            self.conversation_history = ([system_msg] if system_msg else []) + recent_msgs
        
        # è°ƒç”¨LLM
        response = self.llm_client.chat_completion(self.conversation_history)
        
        # è§£æå“åº”
        action, target = self._parse_response(response, observation)
        
        # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
        self.conversation_history.append({
            "role": "assistant",
            "content": f"æˆ‘é€‰æ‹©: {action} {target or ''}"
        })
        
        return action, target
    
    def _build_prompt(self, observation: Dict[str, Any]) -> str:
        """æ„å»ºæç¤º"""
        location = observation.get('agent_location', 'æœªçŸ¥ä½ç½®')
        inventory = observation.get('agent_inventory', [])
        visible_entities = observation.get('visible_entities', [])
        available_actions = observation.get('available_actions', [])
        description = observation.get('description', 'æ²¡æœ‰æè¿°')
        
        prompt = f"""
å½“å‰çŠ¶æ€:
- ä½ç½®: {location}
- åº“å­˜: {inventory if inventory else 'ç©º'}
- å¯è§ç‰©å“: {visible_entities if visible_entities else 'æ— '}
- å¯ç”¨åŠ¨ä½œ: {available_actions if available_actions else 'æ— '}
- ç¯å¢ƒæè¿°: {description}

è¯·é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œã€‚å›å¤æ ¼å¼: "åŠ¨ä½œ ç›®æ ‡" (å¦‚æœä¸éœ€è¦ç›®æ ‡åˆ™åªå›å¤åŠ¨ä½œ)
ä¾‹å¦‚: "pick_up Apple" æˆ– "examine Cabinet" æˆ– "wait"

ä½ çš„é€‰æ‹©:"""
        
        return prompt
    
    def _parse_response(self, response: str, observation: Dict[str, Any]) -> tuple[str, str]:
        """è§£æLLMå“åº”"""
        response = response.strip().lower()
        available_actions = observation.get('available_actions', [])
        visible_entities = observation.get('visible_entities', [])
        
        # å°è¯•è§£æ "åŠ¨ä½œ ç›®æ ‡" æ ¼å¼
        parts = response.split()
        if len(parts) >= 2:
            action = parts[0]
            target = ' '.join(parts[1:])
            
            # éªŒè¯åŠ¨ä½œæ˜¯å¦å¯ç”¨
            if action in available_actions:
                # éªŒè¯ç›®æ ‡æ˜¯å¦å­˜åœ¨
                if any(target.lower() in entity.lower() for entity in visible_entities):
                    return action, target
        
        # å°è¯•å•ä¸ªåŠ¨ä½œ
        if len(parts) >= 1:
            action = parts[0]
            if action in available_actions:
                if action in ['wait', 'look']:
                    return action, None
                elif visible_entities:
                    return action, visible_entities[0]
        
        # å¤‡ç”¨ç­–ç•¥
        if available_actions:
            if 'pick_up' in available_actions and visible_entities:
                return 'pick_up', visible_entities[0]
            elif 'examine' in available_actions and visible_entities:
                return 'examine', visible_entities[0]
            else:
                return available_actions[0], visible_entities[0] if visible_entities else None
        
        return 'wait', None
    
    def update(self, observation: Dict[str, Any], action: str, target: str, 
               reward: float, next_observation: Dict[str, Any], done: bool):
        """æ›´æ–°æ™ºèƒ½ä½“"""
        # æ·»åŠ ç»“æœåé¦ˆåˆ°å¯¹è¯å†å²
        feedback = f"æ‰§è¡Œ {action} {target or ''} åï¼Œè·å¾—å¥–åŠ± {reward:.2f}"
        if done:
            feedback += "ï¼Œä»»åŠ¡å®Œæˆï¼" if reward > 0 else "ï¼Œä»»åŠ¡å¤±è´¥ã€‚"
        
        self.conversation_history.append({
            "role": "user",
            "content": f"åé¦ˆ: {feedback}"
        })
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'agent_type': 'real_llm_baseline',
            'model': self.llm_client.model,
            'conversation_length': len(self.conversation_history),
            'api_calls': len([msg for msg in self.conversation_history if msg['role'] == 'assistant'])
        }


if __name__ == "__main__":
    # æµ‹è¯•LLMå®¢æˆ·ç«¯
    print("ğŸ§ª æµ‹è¯•LLMå®¢æˆ·ç«¯")
    
    api_key = "sk-rvwMvUNbWBz9L76KB05650C7Cc464324BdC98dB3FbD4296a"
    
    # æµ‹è¯•LLMå®¢æˆ·ç«¯
    client = LLMClient(api_key)
    
    test_messages = [
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
    ]
    
    response = client.chat_completion(test_messages)
    print(f"LLMå“åº”: {response}")
    
    # æµ‹è¯•LLMæ™ºèƒ½ä½“
    agent = LLMBaselineAgent(api_key)
    
    mock_observation = {
        'scene': 'FloorPlan228-openable',
        'agent_location': 'Kitchen',
        'agent_inventory': [],
        'visible_entities': ['Cabinet', 'Drawer', 'Apple', 'Key'],
        'available_actions': ['go_to', 'open', 'pick_up', 'examine', 'wait'],
        'description': 'ä½ åœ¨å¨æˆ¿é‡Œï¼Œå¯ä»¥çœ‹åˆ°æŸœå­ã€æŠ½å±‰ã€è‹¹æœå’Œé’¥åŒ™ã€‚'
    }
    
    action, target = agent.select_action(mock_observation)
    print(f"æ™ºèƒ½ä½“é€‰æ‹©: {action} {target or ''}")
    
    print("âœ… æµ‹è¯•å®Œæˆ")
