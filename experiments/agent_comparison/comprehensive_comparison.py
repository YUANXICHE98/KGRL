"""
å®Œæ•´çš„çœŸå®RAG vs Baselineå®éªŒ
ç¡®ä¿æ•°æ®æ­£ç¡®ä¿å­˜åˆ°results/real_rag_vs_baseline/data/
"""

import sys
import time
import json
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.agents.baseline_agent import BaselineAgent
from src.agents.react_agent import ReactAgent
from src.environments.textworld_env import TextWorldEnvironment
from src.knowledge.kg_builder import KnowledgeGraphBuilder
from src.knowledge.kg_retriever import KnowledgeGraphRetriever
from src.utils.experiment_logger import ExperimentLogger
from src.utils.logger import get_logger

def create_comprehensive_knowledge_graph():
    """åˆ›å»ºå…¨é¢çš„æ¸¸æˆçŸ¥è¯†å›¾è°±"""
    kg = KnowledgeGraphBuilder('comprehensive_game_knowledge')
    
    # æˆ¿é—´ç»“æ„
    kg.add_fact('kitchen', 'type', 'room')
    kg.add_fact('bedroom', 'type', 'room')
    kg.add_fact('kitchen', 'connects_to', 'bedroom')
    kg.add_fact('bedroom', 'connects_to', 'kitchen')
    
    # æˆ¿é—´å†…å®¹
    kg.add_fact('kitchen', 'contains', 'fridge')
    kg.add_fact('kitchen', 'contains', 'table')
    kg.add_fact('kitchen', 'contains', 'key')
    kg.add_fact('bedroom', 'contains', 'chest')
    kg.add_fact('bedroom', 'contains', 'bed')
    
    # ç‰©å“å±æ€§
    kg.add_fact('fridge', 'type', 'container')
    kg.add_fact('fridge', 'contains', 'apple')
    kg.add_fact('fridge', 'can_be', 'opened')
    kg.add_fact('chest', 'type', 'container')
    kg.add_fact('chest', 'contains', 'treasure')
    kg.add_fact('chest', 'requires', 'key')
    kg.add_fact('key', 'type', 'item')
    kg.add_fact('key', 'opens', 'chest')
    kg.add_fact('apple', 'type', 'food')
    
    # åŠ¨ä½œçŸ¥è¯†
    kg.add_fact('take', 'works_with', 'key')
    kg.add_fact('take', 'works_with', 'apple')
    kg.add_fact('open', 'works_with', 'chest')
    kg.add_fact('open', 'works_with', 'fridge')
    kg.add_fact('go', 'direction', 'north')
    kg.add_fact('go', 'direction', 'south')
    
    # ç­–ç•¥çŸ¥è¯†
    kg.add_fact('strategy', 'first_step', 'find_key')
    kg.add_fact('strategy', 'second_step', 'go_to_bedroom')
    kg.add_fact('strategy', 'final_step', 'open_chest')
    kg.add_fact('goal', 'requires', 'key_and_chest')
    
    return kg

def run_single_agent_episodes(agent, env, agent_type, num_episodes=8):
    """è¿è¡Œå•ä¸ªAgentçš„episodeså¹¶è¿”å›ç»“æœæ•°æ®"""
    logger = get_logger(f"{agent_type}_Experiment")
    results = []
    
    for episode in range(num_episodes):
        logger.info(f"å¼€å§‹ {agent_type} Episode {episode + 1}/{num_episodes}")
        
        # è®°å½•episodeå¼€å§‹æ—¶é—´
        episode_start_time = time.time()
        
        # é‡ç½®ç¯å¢ƒå’ŒAgent
        observation = env.reset()
        if hasattr(agent, 'reset'):
            agent.reset()
        
        # Episodeæ•°æ®
        episode_data = {
            'episode_id': episode,
            'agent_type': agent_type,
            'model_name': getattr(agent, 'model_name', 'gpt-4o'),
            'environment': 'TextWorld_Simulated',
            'difficulty': 'easy',
            'use_knowledge_graph': getattr(agent, 'use_knowledge_graph', False),
            'use_react_reasoning': getattr(agent, 'use_react_reasoning', False),
            'temperature': getattr(agent, 'temperature', 0.7),
            'max_tokens': getattr(agent, 'max_tokens', 150),
            'actions_taken': [],
            'invalid_actions': 0,
            'kg_queries': 0,
            'kg_hits': 0,
            'api_calls': 0,
            'api_response_times': [],
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        total_reward = 0
        done = False
        step_count = 0
        max_steps = 30
        
        logger.debug(f"åˆå§‹è§‚å¯Ÿ: {observation}")
        
        while not done and step_count < max_steps:
            # è·å–å¯ç”¨åŠ¨ä½œ
            available_actions = env.get_available_actions()
            
            # Agentå†³ç­–
            start_time = time.time()
            try:
                action = agent.act(observation, available_actions)
                api_time = time.time() - start_time
                is_valid = action in available_actions
                
                # è®°å½•APIè°ƒç”¨
                episode_data['api_calls'] += 1
                episode_data['api_response_times'].append(api_time)
                episode_data['actions_taken'].append(action)
                
                if not is_valid:
                    episode_data['invalid_actions'] += 1
                
                logger.debug(f"Agenté€‰æ‹©: {action} (æœ‰æ•ˆ: {is_valid}, æ—¶é—´: {api_time:.2f}s)")
                
            except Exception as e:
                logger.error(f"Agentå†³ç­–å¤±è´¥: {e}")
                action = available_actions[0] if available_actions else "look"
                api_time = time.time() - start_time
                is_valid = False
                episode_data['invalid_actions'] += 1
            
            # è®°å½•RAG Agentçš„KGä½¿ç”¨æƒ…å†µ
            if hasattr(agent, 'kg_queries') and hasattr(agent, 'kg_hits'):
                episode_data['kg_queries'] = agent.kg_queries
                episode_data['kg_hits'] = agent.kg_hits
            
            # æ‰§è¡ŒåŠ¨ä½œ
            observation, reward, done, info = env.step(action)
            total_reward += reward
            step_count += 1
            
            logger.debug(f"Step {step_count}: å¥–åŠ±={reward}, å®Œæˆ={done}")
            
            if done and reward > 0:
                logger.info(f"ğŸ‰ {agent_type} Episode {episode + 1} æˆåŠŸå®Œæˆä»»åŠ¡ï¼")
                break
        
        # å®Œæˆepisode
        episode_end_time = time.time()
        success = done and total_reward > 0
        
        episode_data.update({
            'success': success,
            'total_steps': step_count,
            'total_reward': total_reward,
            'completion_time': episode_end_time - episode_start_time
        })
        
        results.append(episode_data)
        
        logger.info(f"{agent_type} Episode {episode + 1} å®Œæˆ: "
                   f"æˆåŠŸ={success}, æ­¥æ•°={step_count}, å¥–åŠ±={total_reward:.3f}")
        
        # æ˜¾ç¤ºRAGç»Ÿè®¡
        if hasattr(agent, 'get_stats'):
            stats = agent.get_stats()
            if stats.get('kg_queries', 0) > 0:
                logger.info(f"  KGä½¿ç”¨: æŸ¥è¯¢={stats['kg_queries']}, "
                           f"å‘½ä¸­={stats['kg_hits']}, å‘½ä¸­ç‡={stats['kg_hit_rate']:.2%}")
    
    return results

def save_experiment_data(baseline_results, rag_results, output_dir="results/real_rag_vs_baseline"):
    """ä¿å­˜å®éªŒæ•°æ®"""
    output_path = Path(output_dir)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    data_dir = output_path / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_results = baseline_results + rag_results
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜JSONæ ¼å¼
    json_file = data_dir / f"real_experiment_results_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜CSVæ ¼å¼
    import pandas as pd
    csv_file = data_dir / f"real_experiment_results_{timestamp}.csv"
    df = pd.DataFrame(all_results)
    df.to_csv(csv_file, index=False)
    
    print(f"âœ… å®éªŒæ•°æ®å·²ä¿å­˜:")
    print(f"  JSON: {json_file}")
    print(f"  CSV: {csv_file}")
    
    return json_file, csv_file, all_results

def run_complete_real_experiment():
    """è¿è¡Œå®Œæ•´çš„çœŸå®å®éªŒ"""
    print("ğŸš€ å®Œæ•´çœŸå®RAG vs Baselineå®éªŒ")
    print("=" * 60)
    print("è¿™å°†ä½¿ç”¨:")
    print("  âœ… çœŸå®GPT-4o APIè°ƒç”¨")
    print("  âœ… çœŸå®çŸ¥è¯†å›¾è°±æ£€ç´¢")
    print("  âœ… çœŸå®ReActæ¨ç†")
    print("  âœ… å®Œæ•´æ•°æ®ä¿å­˜")
    
    # åˆ›å»ºç¯å¢ƒ
    env = TextWorldEnvironment('complete_real_exp', {
        'difficulty': 'easy',
        'max_episode_steps': 30
    })
    
    # åˆ›å»ºçŸ¥è¯†å›¾è°±
    print("\nğŸ“š æ„å»ºçŸ¥è¯†å›¾è°±...")
    kg = create_comprehensive_knowledge_graph()
    retriever = KnowledgeGraphRetriever(kg, 'complete_retriever')
    print(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ: {len(kg.facts)} ä¸ªäº‹å®")
    
    # åˆ›å»ºBaseline Agent
    print("\nğŸ¤– åˆ›å»ºBaseline Agent...")
    baseline_agent = BaselineAgent('baseline_complete', {
        'model_name': 'gpt-4o',
        'use_local_model': False,
        'temperature': 0.7,
        'max_tokens': 150
    })
    
    # åˆ›å»ºReact Agent
    print("ğŸ§  åˆ›å»ºReact Agent...")
    react_agent = ReactAgent('react_complete', {
        'model_name': 'gpt-4o',
        'use_local_model': False,
        'use_knowledge_graph': True,
        'use_react_reasoning': True,
        'temperature': 0.7,
        'max_tokens': 200,
        'max_kg_facts': 5
    })
    react_agent.set_knowledge_retriever(retriever)

    # è¿è¡Œå®éªŒ
    print("\nğŸ”¬ è¿è¡ŒBaseline Agentå®éªŒ...")
    baseline_results = run_single_agent_episodes(baseline_agent, env, "Baseline_LLM_Real", 6)

    print("\nğŸ”¬ è¿è¡ŒReact Agentå®éªŒ...")
    react_results = run_single_agent_episodes(react_agent, env, "React_LLM_Real", 6)
    
    # ä¿å­˜æ•°æ®
    print("\nğŸ’¾ ä¿å­˜å®éªŒæ•°æ®...")
    json_file, csv_file, all_results = save_experiment_data(baseline_results, react_results)
    
    # ç”Ÿæˆæ‘˜è¦
    print("\nğŸ“Š å®éªŒç»“æœæ‘˜è¦:")
    baseline_success = sum(1 for r in baseline_results if r['success']) / len(baseline_results)
    react_success = sum(1 for r in react_results if r['success']) / len(react_results)

    print(f"  Baseline Agent: {baseline_success:.1%} æˆåŠŸç‡")
    print(f"  React Agent: {react_success:.1%} æˆåŠŸç‡")
    print(f"  æ”¹è¿›: {(react_success - baseline_success):.1%}")
    
    return json_file, csv_file

if __name__ == "__main__":
    confirm = input("ç¡®è®¤è¿è¡Œå®Œæ•´çœŸå®å®éªŒ? (y/N): ").strip().lower()
    if confirm == 'y':
        run_complete_real_experiment()
    else:
        print("å®éªŒå–æ¶ˆ")
